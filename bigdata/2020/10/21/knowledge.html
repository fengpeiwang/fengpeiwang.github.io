<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fengpeiwang.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="需求123如何从一个海量文件中寻找出现次数最多的10个元素？（TopN）如何从两个大数据集中找出共同元素？（求交集）如何设计一个高效算法判断一个元素是否存在于一个庞大集合内？（布隆过滤器）">
<meta property="og:type" content="article">
<meta property="og:title" content="Knowledge">
<meta property="og:url" content="http://fengpeiwang.github.io/bigdata/2020/10/21/knowledge.html">
<meta property="og:site_name" content="夜猫的啼叫">
<meta property="og:description" content="需求123如何从一个海量文件中寻找出现次数最多的10个元素？（TopN）如何从两个大数据集中找出共同元素？（求交集）如何设计一个高效算法判断一个元素是否存在于一个庞大集合内？（布隆过滤器）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://fengpeiwang.github.io/images/img/image-20200506224907986.png">
<meta property="og:image" content="http://fengpeiwang.github.io/images/img/image-20200506224817897.png">
<meta property="og:image" content="http://fengpeiwang.github.io/images/img/image-20200506230144060.png">
<meta property="og:image" content="http://fengpeiwang.github.io/images/img/image-20200511080727192.png">
<meta property="og:image" content="http://fengpeiwang.github.io/images/img/image-20200511080756953.png">
<meta property="og:image" content="http://fengpeiwang.github.io/images/img/hivestructure.png">
<meta property="og:image" content="http://fengpeiwang.github.io/images/img/rdddfds.png">
<meta property="og:image" content="http://fengpeiwang.github.io/images/img/image-20200507080745974.png">
<meta property="og:image" content="http://fengpeiwang.github.io/Users/wangfeng/Library/Application%20Support/typora-user-images/image-20200507082432134.png">
<meta property="article:published_time" content="2020-10-21T12:00:54.000Z">
<meta property="article:modified_time" content="2020-10-27T03:19:57.739Z">
<meta property="article:author" content="阿峰">
<meta property="article:tag" content="面试">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://fengpeiwang.github.io/images/img/image-20200506224907986.png">

<link rel="canonical" href="http://fengpeiwang.github.io/bigdata/2020/10/21/knowledge.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Knowledge | 夜猫的啼叫</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">夜猫的啼叫</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fengpeiwang.github.io/bigdata/2020/10/21/knowledge.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/logo/Jourdan.jpeg">
      <meta itemprop="name" content="阿峰">
      <meta itemprop="description" content="每一天都是一个开始。深呼吸，从头再来。永远不要埋怨你已经发生的事情，要么就改变它，要么就安静的接受它">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="夜猫的啼叫">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Knowledge
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-21 20:00:54" itemprop="dateCreated datePublished" datetime="2020-10-21T20:00:54+08:00">2020-10-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-27 11:19:57" itemprop="dateModified" datetime="2020-10-27T11:19:57+08:00">2020-10-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h4 id="需求"><a href="#需求" class="headerlink" title="需求"></a><strong>需求</strong></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">如何从一个海量文件中寻找出现次数最多的10个元素？（TopN）</span><br><span class="line">如何从两个大数据集中找出共同元素？（求交集）</span><br><span class="line">如何设计一个高效算法判断一个元素是否存在于一个庞大集合内？（布隆过滤器）</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h5 id="求TopN"><a href="#求TopN" class="headerlink" title="求TopN"></a>求TopN</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">数据量小：先排序，然后limit 3</span><br><span class="line">数据量大：先分区&#x2F;分桶（把数据先分成多个小的组成部分，每个小的部分都单独计算出来 N 个最大的</span><br><span class="line">最终把每个小部分计算出来的 N 个最大的，做最终的汇总</span><br><span class="line"></span><br><span class="line">eg. 如果现在有1W张扑克牌。给我找出最大的10张扑克牌</span><br><span class="line">分布式的计算应用程序应该要分成两个阶段：</span><br><span class="line"> 1、映射阶段； mapper</span><br><span class="line">  一个大文件切分成了多个小文件，可以进行并行计算</span><br><span class="line"> 2、聚合阶段： reducer</span><br><span class="line">  最重要得到统一的结果，必须要聚合！</span><br></pre></td></tr></table></figure>

<h5 id="求交集"><a href="#求交集" class="headerlink" title="求交集"></a>求交集</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">假如文件a和文件b都特别大： </span><br><span class="line">现在求出共同的元素：</span><br><span class="line"> 1、采用的思路依然是分治法</span><br><span class="line"> 2、关键在于怎么分治（随机，范围，Hash散列，....）</span><br><span class="line">做Hash散列（行业通用的默认做法）</span><br><span class="line"> a文件拆分成 10个文件：</span><br><span class="line"> b文件拆分成10个文件： </span><br><span class="line"> a1 和 b1 找共同元素就可以</span><br><span class="line"> a2 和 b2 找共同元素</span><br><span class="line"> ..... </span><br></pre></td></tr></table></figure>

<h5 id="判断元素是否存在"><a href="#判断元素是否存在" class="headerlink" title="判断元素是否存在"></a>判断元素是否存在</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">数据量小： </span><br><span class="line"> java中的hashset</span><br><span class="line">  redis的set</span><br><span class="line">如果数据量很大：</span><br><span class="line"> 布隆过滤器（更强大的位图算法）</span><br><span class="line"> 实现快速判断一个元素是否存在</span><br><span class="line"> 优点：快速判断（爬虫: url判重）</span><br><span class="line"> 缺点：误判</span><br></pre></td></tr></table></figure>

<h5 id="思考：使用Hadoop-java-api"><a href="#思考：使用Hadoop-java-api" class="headerlink" title="思考：使用Hadoop java api"></a>思考：使用Hadoop java api</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、删除某个文件夹下的所有空文件夹！（子层空文件删除之后，父层又成了空文件，情况处理）</span><br><span class="line">2、删除某个目录下指定的某种类型的文件</span><br></pre></td></tr></table></figure>



<hr>
<h4 id="知识点-Hadoop"><a href="#知识点-Hadoop" class="headerlink" title="知识点 Hadoop"></a>知识点 Hadoop</h4><h5 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么?"></a>Hadoop是什么?</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Hadoop是Apache下的一套高可靠，高可扩展，对海量数据进行分布式处理(存储和计算) 的开源软件平台hadoop 的组成</span><br><span class="line">1.Common    (基础功能组件)(工具包，RPC框架)JNDI和 RPC</span><br><span class="line">2.HDFS      (Hadoop Distributed File System分布式文件系统)</span><br><span class="line">3.YARN      (Yet Another Resources Negotiator运算资源调度系统) </span><br><span class="line">4.MapReduce (Map和Reduce分布式运算编程框架)</span><br></pre></td></tr></table></figure>

<h5 id="分布式集群的架构"><a href="#分布式集群的架构" class="headerlink" title="分布式集群的架构"></a>分布式集群的架构</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">分布式集群的架构，一般有对等架构和主从架构，对等架构实现起来要复杂一些。</span><br><span class="line"> 对等架构: 所有节点都可以对外提供服务，某一台节点宕机了，另外两台仍旧可以快速响应，几乎不受影响</span><br><span class="line"> 主从架构: 主要压力在主节点，主节点对外对内都需要提供服务。</span><br></pre></td></tr></table></figure>

<h5 id="HDFS的设计思想"><a href="#HDFS的设计思想" class="headerlink" title="HDFS的设计思想"></a>HDFS的设计思想</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HDFS的设计目的： 解决海量数据的存储问题</span><br><span class="line">HDFS的设计思想：</span><br><span class="line"> 1、分块存储</span><br><span class="line">  把一个大文件切分成多个小文件，每一个节点存储一部分小文件 使用一个集群来联合存储这个文件</span><br><span class="line"> 2、冗余存储</span><br><span class="line">  一个数据块存储多个副本。多个副本分散存储在多个不同的节点上。提高副本数，有助于提高数据安全性</span><br><span class="line">  并为之后的运算分析提供数据存储支撑</span><br></pre></td></tr></table></figure>

<h5 id="HDFS怎么保证高效？"><a href="#HDFS怎么保证高效？" class="headerlink" title="HDFS怎么保证高效？"></a>HDFS怎么保证高效？</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1、机架感知，保证数据块的存放有一个最高效的策略</span><br><span class="line">2、负载均衡</span><br><span class="line">3、安全模式</span><br><span class="line">4、Trash机制</span><br><span class="line">5、Archeive归档解决海量小文件存储问题</span><br><span class="line">6、执行流时数据访问</span><br><span class="line">7、执行自动副本维护</span><br></pre></td></tr></table></figure>

<h5 id="HDFS如何保证数据安全"><a href="#HDFS如何保证数据安全" class="headerlink" title="HDFS如何保证数据安全"></a>HDFS如何保证数据安全</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">副本存储 默认3副本 副本存放策略，当前机架当前机器，当前机架不同机器，不同机架的不同机器 确保数据不丢失</span><br><span class="line">机架感知 </span><br><span class="line">心跳机制 datanode已block为单位，每3s报告心跳状态，做10min + 30s内不报告心跳状态则namenode认为block已死掉，</span><br><span class="line"> namonode会把其上面的数据备份到其他一个datanode节点上，保证数据的副本数量；</span><br><span class="line">安全模式</span><br></pre></td></tr></table></figure>

<h5 id="分布式文件系统的设计原则"><a href="#分布式文件系统的设计原则" class="headerlink" title="分布式文件系统的设计原则"></a>分布式文件系统的设计原则</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">第一，可靠（可扩展(动态伸缩)，可维护，高可用(7*24)）</span><br><span class="line">第二，高效（追求极致）</span><br></pre></td></tr></table></figure>

<h5 id="HDFS的组织架构"><a href="#HDFS的组织架构" class="headerlink" title="HDFS的组织架构"></a>HDFS的组织架构</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">namenode主节点：  整个文件系统的元数据</span><br><span class="line"> 既存储在内存中，完整一份，保证安全又存储在磁盘中完整一份，提高效</span><br><span class="line"> 磁盘；读写慢，数据安全</span><br><span class="line"> 内存：读写快，但是掉电丢失数据</span><br><span class="line"></span><br><span class="line">secondarynamenode</span><br><span class="line"> 作用：定期给namenode去合并磁盘元数据</span><br><span class="line"> 目的：为了降低namenode的负载 </span><br><span class="line"> </span><br><span class="line">DataNode</span><br><span class="line"> 作用：负责管理用户的文件数据块，文件会按照固定的大小（blocksize）切成若干块后分布式存储在</span><br><span class="line"> 若干台datanode上，每一个文件块可以有多个副本，并存放在不同的datanode上，Datanode会定期向</span><br><span class="line"> Namenode汇报自身所保存的文件block信息，而namenode则会负责保持文件的副本数量</span><br></pre></td></tr></table></figure>

<h5 id="HDFS概念和特性"><a href="#HDFS概念和特性" class="headerlink" title="HDFS概念和特性"></a>HDFS概念和特性</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">概念：hdfs是一个分布式文件系统，通过统一的命名空间(类似于Linux文件系统的目录树)来 定位文件，由多个节点联合起来实现文件的</span><br><span class="line">存储，每个节点都有各自的角色。</span><br><span class="line">特性：</span><br><span class="line"> 1、分块存储，hadoop2.x默认的块的大小是128M。可以通过dfs.blocksize进行设置</span><br><span class="line"> 2、可以通过hdfs命令 + 抽象文件目录访问文件</span><br><span class="line"> 3、元数据(目录树结构及文件分块位置信息)的管理由NameNode节点承担</span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<h5 id="HDFS关于小文件的解决"><a href="#HDFS关于小文件的解决" class="headerlink" title="HDFS关于小文件的解决"></a>HDFS关于小文件的解决</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1、同种类型的小文件可以考虑合并</span><br><span class="line">2、建立成归档文件</span><br><span class="line">3、如果涉及到计算问题，那么一定要要进行自定义，让mapreduce程序按照我们的自定义逻辑是先</span><br><span class="line">默认情况下：一个HDFS的文件的数据块，就会针对性的启动一个小任务</span><br><span class="line">说明：每个文件的切块大小：不能太大，也不能太小</span><br><span class="line">太小：</span><br><span class="line"> 1.导致每个文件块启动一个计算任务，但是计算的数据量非常小，大量的性能消耗在启动任务上</span><br><span class="line">   不好配合计算, 也会造成元数据太多，给namenode造成压力</span><br><span class="line"> 2.存取文件消耗的寻道时间远远大于读取计算所用的时间</span><br><span class="line">太大：不能使数据均匀分布到整个HDFS，没法充分利用整个HDFS的性能</span><br><span class="line"> </span><br><span class="line">HDFS不适合存小文件的原因：</span><br><span class="line">  元信息存储在NameNode内存中，一个节点的内存是有限的 存取大量小文件消耗大量的寻道时间，类比拷贝大量小</span><br><span class="line">  文件与拷贝同等大小的一个大文件 NameNode存储block数目是有限的，一个block元信息消耗大约150 byte内</span><br><span class="line">  存，存储1亿个block，大约 需要20GB内存</span><br><span class="line">  如果一个文件大小为10K，则1亿个文件大小仅为1TB(但要消耗掉NameNode 20GB内存)</span><br><span class="line">  </span><br><span class="line">面试题：</span><br><span class="line">小文件的优化</span><br><span class="line">客户端：先将文件合并然后在上传hdfs(cat &#x2F;file&#x2F;* &gt;&gt; merge.txt) 局限：不支持列式存储parquet </span><br><span class="line">程序段：读取的时候使用mapreduce程序进行合并落地hdfs</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="HDFS文件块丢失对数据是否会有影响"><a href="#HDFS文件块丢失对数据是否会有影响" class="headerlink" title="HDFS文件块丢失对数据是否会有影响"></a>HDFS文件块丢失对数据是否会有影响</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">如果丢了一个副本，这是没关系的，因为数据块有多个副本（默认是3个副本）。HDFS的内部，会有一个自动维护机制：</span><br><span class="line">定期汇报维护所有数据块的副本个数，是否满足客户端要求的个数。发现副本数多了，会删掉。发现副本数少了，</span><br><span class="line">会复制出来，始终保持对应的副本数</span><br><span class="line">注意： 如果丢失了一个数据块的所有副本，无法恢复</span><br><span class="line">提供副本数，可以提高数据的安全性，但是副本数过多比较消耗磁盘空间</span><br></pre></td></tr></table></figure>

<h5 id="HDFS优缺点"><a href="#HDFS优缺点" class="headerlink" title="HDFS优缺点"></a>HDFS优缺点</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line"> 1.构建在廉价机器上，通过多副本提高可靠性，提供了容错和恢复机制</span><br><span class="line"> 2.高容错性，数据自动保存多个副本，副本丢失后，自动恢复，增加副本，提高容错性 副本丢失，HDFS的内部机制可自动恢复。</span><br><span class="line"> 3.适合批处理，移动计算而非数据，数据位置暴露给计算框架</span><br><span class="line"> （程序找数据，数据在哪个节点，就到哪个节点启动任务，所以一般nodemanager 和 datanode 安装在同一个节点方便计算）</span><br><span class="line"> 4.适合大量数据处理 （数据规模:GB、TB、甚至PB级数据 ）</span><br><span class="line"> 5.文件一次性写入，多次读取。 保证数据一致性</span><br><span class="line"> </span><br><span class="line">缺点：</span><br><span class="line"> 1.数据访问有延迟</span><br><span class="line"> 2.小文件存取 占用NameNode大量内存并且耗时（寻道时间超过读取时间）</span><br><span class="line"> 3.并发写入、不支持文件随机修改 仅支持 append，不支持update（如果修改导致数据一致性问题）</span><br><span class="line"> 4.如果副本数比较大，那么这个HDFS集群是比较消耗磁盘空间的！</span><br></pre></td></tr></table></figure>

<h5 id="HDFS核心设计之架构与心跳机制"><a href="#HDFS核心设计之架构与心跳机制" class="headerlink" title="HDFS核心设计之架构与心跳机制"></a>HDFS核心设计之架构与心跳机制</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1.Hadoop 中包含了两个独立的主从架构(Master &#x2F; Slave)的集群:HDFS 和 YARN </span><br><span class="line"> HDFS的主节点的守护进程是:NameNode，从节点的守护进程是 DataNode， </span><br><span class="line"> YARN的主节点的守护进程是:ResourceManager，从节点的守护进程是 NodeManager</span><br><span class="line">2.Master 启动的时候会启动一个 IPC(Inter-Process Comunication，进程间通信)Server服务，等待Slave </span><br><span class="line"> 的链接</span><br><span class="line">3.Slave 启动时，会主动链接 Master 的 IPC 服务，并且每隔3秒链接一次 Master （dfs.heartbeat.interval）</span><br><span class="line"> 称为心跳。Slave 通过心跳汇报自己的信息给Master，Master也通过心跳给Slave下达命令</span><br><span class="line">4.NameNode 通过心跳得知 DataNode 的状态，ResourceManager 通过心跳得知 NodeManager 的状态</span><br><span class="line">5.如果 master 长时间都没有收到 slave 的心跳，就认为该slave挂掉了。</span><br><span class="line">默认：HDFS 默认的超时时间为10分钟+30秒,也就是630s. 这里暂且定义超时时间为timeout计算公式为：</span><br><span class="line"> timeout &#x3D; 2 * heartbeat.recheck.interval + 10 * dfs.heartbeat.interval</span><br></pre></td></tr></table></figure>

<h5 id="HDFS核心设计之HDFS安全模式"><a href="#HDFS核心设计之HDFS安全模式" class="headerlink" title="HDFS核心设计之HDFS安全模式"></a>HDFS核心设计之HDFS安全模式</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">NameNode的三种状态 (active &#x2F; standby &#x2F; safemode 安全模式)</span><br><span class="line">问题:</span><br><span class="line"> 1.集群启动后，可以查看但是不可以进行update，web页面显示NameNode处于SafeMode状态怎么处理?</span><br><span class="line"> 第一种情况： </span><br><span class="line">  如果HDFS集群正常启动时，等待它自动退出安全模式。</span><br><span class="line"> 第二种情况：</span><br><span class="line">  手动强制退出安全模式 </span><br><span class="line"> 2.什么情况下NameNode会进入安全模式？</span><br><span class="line">  a.NameNode发现集群中的 block 丢失率达到一定比例时(0.1%)，NameNode就会进入安全模式</span><br><span class="line">  b.集群启动过程中会进入安全模式</span><br><span class="line"> </span><br><span class="line"> 3.正常启动的时候进入安全的原理:</span><br><span class="line">  1.NameNode的内存元数据中，包含文件存储目录的路径、副本数、blockid，及每一个block所在 </span><br><span class="line">   DataNode的信息，而fsimage中，不包含block所在的DataNode信息</span><br><span class="line">  2.当NameNode冷（断电）启动时，此时内存中的元数据只能从fsimage中加载而来，如果没有block所在的 </span><br><span class="line">   DataNode信息，就会导致NameNode认为所有的block都已经丢失从而HDFS会自动进入安全模式 </span><br><span class="line">  3.伴随着每个DataNode启动后，会定期向NameNode汇报自身所持有的blockid信息，随着DataNode</span><br><span class="line">   陆续启动，从而陆续汇报block信息，NameNode就会将内存元数据中的block所在DataNode信息补全更新</span><br><span class="line">  4.当HDFS集群中的每个文件都找到了所有block的位置，从而自动退出安全模式</span><br><span class="line">  </span><br><span class="line">  安全模式常用操作命令:</span><br><span class="line">   hdfs dfsadmin -safemode leave &#x2F;&#x2F;强制NameNode退出安全模式  </span><br><span class="line">   hdfs dfsadmin -safemode enter &#x2F;&#x2F;进入安全模式</span><br><span class="line">   hdfs dfsadmin -safemode get   &#x2F;&#x2F;查看安全模式状态</span><br><span class="line">   hdfs dfsadmin -safemode wait  &#x2F;&#x2F;等待，一直到安全模式结束</span><br><span class="line"></span><br><span class="line"> 安全模式下用户可以进行的操作(不修改元数据的操作):ls查询、cat查看文件内容、get下载 </span><br><span class="line"> 安全模式下用户不可以进行的操作(修改了元数据的操作):创建目录、上传、修改文件名、文件追加</span><br></pre></td></tr></table></figure>

<h5 id="HDFS核心设计之HDFS副本存放策略"><a href="#HDFS核心设计之HDFS副本存放策略" class="headerlink" title="HDFS核心设计之HDFS副本存放策略"></a>HDFS核心设计之HDFS副本存放策略</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HDFS 分块存储+副本（冗余）存储的策略 是 HDFS 保证可靠性和性能的关键。</span><br><span class="line"> 1.文件分块存储 提高了文件随机读的效率和并发读的效率; </span><br><span class="line"> 2.副本存储到不同的机器节点实现可靠性的同时也提高了同一数据块的并发读效率;</span><br><span class="line">存放策略总结：</span><br><span class="line"> 当前机架当前机器 + 当前机架不同机器 + 不同机架不同机器</span><br></pre></td></tr></table></figure>

<h5 id="HDFS核心设计之HDFS负载均衡"><a href="#HDFS核心设计之HDFS负载均衡" class="headerlink" title="HDFS核心设计之HDFS负载均衡"></a>HDFS核心设计之HDFS负载均衡</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">什么情况下会造成负载？</span><br><span class="line"> 1.在进行文件上传的时候会优先选择客户端所在节点，如果习惯性使用同一个客户端会造成客户端所在节点存储的数</span><br><span class="line">   据比较多。集群会有一个自动的负载均衡的操作，只不过这个负载均衡的操作比较慢。</span><br><span class="line"> 2.集群新增、删除节点</span><br><span class="line"> 3.某个节点机器内硬盘存储达到饱和值。</span><br><span class="line"> 4.当数据不平衡时，Map任务可能会分配到没有存储数据的机器，这将导致网络带宽的消耗，也无法很好的进行本地计算。</span><br><span class="line"></span><br><span class="line">负载均衡导致什么情况发生？</span><br><span class="line"> 当HDFS负载不均衡时，数据分布不均匀，导致热点发生。</span><br><span class="line">  </span><br><span class="line">负载均衡调整的原则：</span><br><span class="line"> 数据平衡不能导致数据块减少，数据块备份丢失 </span><br><span class="line"> 管理员可以中止数据平衡进程 </span><br><span class="line"> 每次移动的数据量以及占用的网络资源，必须是可控的 </span><br><span class="line"> 数据均衡过程，不能影响 namenode 的正常工作</span><br><span class="line">   </span><br><span class="line">start-balancer.sh </span><br></pre></td></tr></table></figure>

<h5 id="HDFS工作机制之概述"><a href="#HDFS工作机制之概述" class="headerlink" title="HDFS工作机制之概述"></a>HDFS工作机制之概述</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1、HDFS 集群分为两大主要角色:NameNode、DataNode，还有两种辅助角色 SecondaryNamenode 和Client</span><br><span class="line">2、NameNode 负责管理整个文件系统的元数据，并且负责响应客户端的请求</span><br><span class="line">3、DataNode 负责管理用户的文件数据块，并且通过心跳机制汇报给 NameNode</span><br><span class="line">4、文件会按照固定的大小 (dfs.blocksize) 切成若干块后分布式存储在若干台 DataNode 上</span><br><span class="line">5、每一个文件块可以有多个副本，并存放在不同的DataNode上</span><br><span class="line">6、DataNode会定期向NameNode汇报自身所保存的文件block信息，而NameNode则会负责保持文件的副本数量</span><br><span class="line">7、HDFS 的内部工作机制对客户端保持透明，客户端请求访问 HDFS 都是通过向 NameNode 申请来进行</span><br></pre></td></tr></table></figure>

<h5 id="HDFS工作机制之写数据流程"><a href="#HDFS工作机制之写数据流程" class="headerlink" title="HDFS工作机制之写数据流程"></a>HDFS工作机制之写数据流程</h5><p><img src="/images/img/image-20200506224907986.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">客户端要向 HDFS 写数据，首先要跟 NameNode 通信以确认可以写文件并获得接收文件 block 的 DataNode，</span><br><span class="line">然后，客户端按顺序将文件逐个 block 传递给相应 DataNode，并由接收到block的DataNode负责向其他DataNode</span><br><span class="line">复制 block 的副本。</span><br><span class="line"> 1、客户端 Client，向远程的 NameNode 发起创建文件请求。</span><br><span class="line"> 2、NameNode 检查要创建的文件是否存在，创建者是否有权限进行操作，如果校验通过则创建文件。</span><br><span class="line"> 3、然后客户端开始写入文件，客户端会将文件切分成多个packets，内部以数据队列“data queue(数据队列)”</span><br><span class="line">  的形式管理packets，向 NameNode申请，用来存储 blocks replicas的合适的DataNode 列表;</span><br><span class="line"> 4、使用pipeline传输数据：DataStreamer 将数据包流式传输到管线第一个DataNode，第一个 DataNode </span><br><span class="line">  再传到第二个DataNode，直到完成。</span><br><span class="line"> 5、最后一个 DataNode 成功存储之后会返回一个 ack packet(确认队列)，在 pipeline 里传递至客户 端，</span><br><span class="line">   在客户端的开发库内部维护着 &quot;ack queue&quot;，成功收到 DataNode 返回的ack packet后会从</span><br><span class="line">   &quot;data queue&quot;移除相应的packet。</span><br><span class="line"> 6、DataNode 收到数据后发送确认，pipeline中所有DataNode的确认组成一个确认队列。所有DataNode都确认，</span><br><span class="line">  管线数据包删除；如果传输过程中，有某个 DataNode出现了故障，那么当前的pipeline 会被关闭，出现故障的 </span><br><span class="line">  DataNode 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 DataNode 中继续以 pipeline 的 </span><br><span class="line">  形式传输，同时NameNode 会分配一个新的 DataNode，保持 replicas 设定的数量。</span><br><span class="line"> 7、客户端完成数据的写入后，会对数据流调用 close() 方法，关闭数据流;</span><br></pre></td></tr></table></figure>

<h5 id="HDFS工作机制之读数据流程"><a href="#HDFS工作机制之读数据流程" class="headerlink" title="HDFS工作机制之读数据流程"></a>HDFS工作机制之读数据流程</h5><p><img src="/images/img/image-20200506224817897.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">客户端将要读取的文件路径发送给 NameNode，NameNode在经过校验之后获取文件的元信息(主要是block的</span><br><span class="line">存放位置信息)返回给客户端，客户端根据返回的信息找到相应 DataNode 逐个获取文件的block并在客户端</span><br><span class="line">本地进行数据追加合并从而获得整个文件。</span><br><span class="line">1、打开文件：客户端调用FileSystem对象的open方法打开文件，获取DistributedFileSystem 的实例; </span><br><span class="line">2、寻址：向NameNode发起rpc请求获取全部block列表以及block的DataNode地址; </span><br><span class="line">3、读取当前block数据：Client选取离客户端最近的DataNode来读取block若客户端本身就是DataNode，本地直接获取数据; </span><br><span class="line">4、读取完当前block的数据后，关闭当前的DataNode链接，读取下一个block; </span><br><span class="line">5、当读完列表block后，且文件读取还没有结束，客户端会继续向NameNode获取下一批的block列表; </span><br><span class="line">6、读取完一个block都会进行checksum验证，如果读取DataNode时出现错误，客户端会通知NameNode，然后再从下</span><br><span class="line">   一个拥有该block拷贝的DataNode继续读。</span><br><span class="line">7. 当客户端读取完毕数据的时候，调用 FSDataInputStream 的 close 方法关闭掉所有的流</span><br></pre></td></tr></table></figure>

<h5 id="NameNode工作机制之职责"><a href="#NameNode工作机制之职责" class="headerlink" title="NameNode工作机制之职责"></a>NameNode工作机制之职责</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NameNode 是 HDFS 的主节点，是负责管理整个 HDFS 集群的，相当于一个团队的老大。</span><br><span class="line">1、负责客户端请求(读写数据请求)的响应</span><br><span class="line">2、管理 HDFS 的元数据:包括命名空间、访问控制信息、文件与数据块的映射关系以及数据块的存储 位置</span><br><span class="line">3、配置和应用副本存放策略</span><br><span class="line">4、管理集群数据块负载均衡问题</span><br></pre></td></tr></table></figure>

<h5 id="NameNode工作机制之元数据存储机制"><a href="#NameNode工作机制之元数据存储机制" class="headerlink" title="NameNode工作机制之元数据存储机制"></a>NameNode工作机制之元数据存储机制</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">NameNode对数据的管理采用了两种存储形式:内存和磁盘 首先是内存中</span><br><span class="line">A、内存中有一份完整的元数据(内存metadata)</span><br><span class="line">B、磁盘有一个“准完整”的元数据镜像(fsimage)文件(在NameNode的工作目录中)</span><br><span class="line">C、用于衔接内存metadata和持久化元数据镜像fsimage之间的操作日志(edits文件)</span><br><span class="line">PS:当客户端对hdfs中的文件进行新增或者修改操作，操作记录首先被记入edits日志文件中，当客户 端操作成功后，相应的</span><br><span class="line">元数据会更新到内存metadata中</span><br><span class="line"></span><br><span class="line">有三种格式:</span><br><span class="line"> 磁盘元数据镜像文件:fsimage_0000000000000000555 </span><br><span class="line"> 历史编辑日志:edits_0000000000000000001-0000000000000000018 </span><br><span class="line"> 数据预写操作日志文件edits_inprogress_0000000000000000556</span><br><span class="line"></span><br><span class="line">元数据的CheckPoint</span><br><span class="line"> 每隔一段时间，会由 SecondaryNamenode 将 NameNode 上积累的所有 edits 和一个最新的 fsimage</span><br><span class="line">下载到本地，并加载到内存进行 merge(这个过程称为 checkpoint)</span><br></pre></td></tr></table></figure>

<h5 id="NameNode工作机制之CheckPoint详细过程图解"><a href="#NameNode工作机制之CheckPoint详细过程图解" class="headerlink" title="NameNode工作机制之CheckPoint详细过程图解:"></a>NameNode工作机制之CheckPoint详细过程图解:</h5><p><img src="/images/img/image-20200506230144060.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">每隔一段时间，会由secondary namenode将namenode上积累的所有edits和一个最新的fsimage下载到本地，</span><br><span class="line">并加载到内存进行merge这个过程称为checkpoint</span><br><span class="line">1、周期性发送请求给NN，获取fsimage和edits; </span><br><span class="line">2、NN收到请求后，生成一个空的edits.new文件 </span><br><span class="line">3、NM给SNN发送fsimage和edits </span><br><span class="line">4、SNN将fsimage文件加载到内存，合并edits文件 </span><br><span class="line">5、snm生成新的镜像文件fsimage.ckpt</span><br><span class="line">6、SNN发送fsimage.ckpt给NN </span><br><span class="line">7、NN将fsimage.ckpt替换fsimage文件，将edits.new重命名为edits文件</span><br><span class="line"></span><br><span class="line">6.5 CheckPoint触发配置</span><br><span class="line">dfs.namenode.checkpoint.check.period&#x3D;60 ##检查触发条件是否满足的频率，60秒 </span><br><span class="line">dfs.namenode.checkpoint.max-retries&#x3D;3 ##最大重试次数 </span><br><span class="line">dfs.namenode.checkpoint.period&#x3D;3600 ##两次checkpoint之间的时间间隔3600秒 </span><br><span class="line">dfs.namenode.checkpoint.txns&#x3D;1000000 ##两次checkpoint之间最大的操作记录</span><br><span class="line"></span><br><span class="line">6.6. CheckPoint附带作用</span><br><span class="line">NameNode 和 SecondaryNamenode 的工作目录存储结构完全相同，所以，当 NameNode 故障退出 需要重新恢复时，可以从 SecondaryNamenode 的工作目录中将 fsimage 拷贝到 NameNode 的工作 目录，以恢复 NameNode 的元数据。</span><br><span class="line">但是请思考:从 SecondaryNamenode复制的fsimage能保证集群的元数据不丢失吗？</span><br></pre></td></tr></table></figure>

<h5 id="DataNode工作机制之工作职责"><a href="#DataNode工作机制之工作职责" class="headerlink" title="DataNode工作机制之工作职责"></a>DataNode工作机制之工作职责</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">存储管理用户文件块的数据</span><br><span class="line">定期向NameNode汇报自身所持有的block信息(通过心跳信息上报)</span><br><span class="line">执行真正的读数据请求</span><br><span class="line"></span><br><span class="line">1、集群容量不够，怎么扩容? 添加新的节点</span><br><span class="line">2、如果有一些 DataNode 宕机，该怎么办? 重新启动</span><br><span class="line">3、DataNode 明明已启动，但是集群中的可用 DataNode 列表中就是没有，怎么办? </span><br><span class="line">1：）datanode机器的配置文件中，指定NameNode的URL不对</span><br><span class="line">2：）NameNode重新格式化了，但是之前的datanode中，data目录下有着之前NameNode的标志，所以不能加入这个集群中</span><br></pre></td></tr></table></figure>

<h5 id="SecondaryNamenode工作机制"><a href="#SecondaryNamenode工作机制" class="headerlink" title="SecondaryNamenode工作机制"></a>SecondaryNamenode工作机制</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SecondaryNamenode的作用就是分担 NameNode 的合并元数据的压力。所以在配置 SecondaryNamenode 的工作节点时，</span><br><span class="line">一定切记，不要和NameNode处于同一节点。事实上，只有在普通的伪分布式集群和分布式集群中才有会SecondaryNamenode </span><br><span class="line">这个角色，在 HA 或者联邦集群 中都不再出现该角色。在 HA 和联邦集群中，都是由 StandbyNameNode 承担。</span><br><span class="line">1、辅助 NameNode，分担其工作量，减轻 NameNode 压力 </span><br><span class="line">2、定期合并 fsimage 和 edits，并推送给 NameNode。 以缩短集群启动的时间。</span><br><span class="line">3、在紧急情况下，可辅助恢复 NameNode。</span><br><span class="line">当NameNode(以下简称NN)失效的时候，Secondary NN并无法立刻提供服务，Secondary NN甚至无 法保证数据完整性:</span><br><span class="line">如果NN数据丢失的话，在上一次合并后的文件系统的改动会丢失。</span><br></pre></td></tr></table></figure>

<h5 id="Hadoop高可用HA"><a href="#Hadoop高可用HA" class="headerlink" title="Hadoop高可用HA"></a>Hadoop高可用HA</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Hadoop HA 同时启动两个NameNode，一个状态为Active，一个状态为Standby，运行中的时Active，不能同时存在2个</span><br><span class="line">Active NameNode。</span><br><span class="line">Standby Namenode与Active Namenode数据保持同步，两个Namenode都与一组Journal Node进行通信。当主Namenode</span><br><span class="line">进行任务的namespace操作时，都会确保namespace的修改持久化到Journal Node节点中。Standby Namenode持续监控这些</span><br><span class="line">edit，当监测到变化时，将这些修改同步到自己的namespace。（保持与Actice NameNode数据一致）</span><br><span class="line">为了确保故障转移能够快速完成，Standby Namenode需要维护最新的Block位置信息，即每个Block副本存放在集群中的哪些节点上。</span><br><span class="line">为了达到这一点，Datanode同时配置主备两个Namenode，并同时发送Block报告和心跳到两台Namenode。</span><br></pre></td></tr></table></figure>

<h5 id="Client-工作机制"><a href="#Client-工作机制" class="headerlink" title="Client 工作机制"></a>Client 工作机制</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Client:就是客户端。</span><br><span class="line">1、文件切分。文件上传 HDFS 的时候，Client 将文件切分成 一个一个的Block，然后进行存储。 </span><br><span class="line">2、与 NameNode 交互，获取文件的位置信息。</span><br><span class="line">3、与 DataNode 交互，读取或者写入数据。</span><br><span class="line">4、Client 提供一些命令来管理 HDFS，比如启动或者关闭HDFS。</span><br><span class="line">5、Client 可以通过一些命令来访问 HDFS。</span><br></pre></td></tr></table></figure>

<h5 id="关于MapperReduce执行机制-执行流程"><a href="#关于MapperReduce执行机制-执行流程" class="headerlink" title="关于MapperReduce执行机制/执行流程"></a>关于MapperReduce执行机制/执行流程</h5><ol>
<li><h6 id="按照数据处理过程来说"><a href="#按照数据处理过程来说" class="headerlink" title="按照数据处理过程来说"></a>按照数据处理过程来说</h6><p><img src="/images/img/image-20200511080727192.png"></p>
</li>
<li><h6 id="按照处理过程中mapperreduce参与的api来说"><a href="#按照处理过程中mapperreduce参与的api来说" class="headerlink" title="按照处理过程中mapperreduce参与的api来说"></a>按照处理过程中mapperreduce参与的api来说</h6><p><img src="/images/img/image-20200511080756953.png"></p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1.一个mr程序启动的时候，最先启动的是MRAppMaster，MRAppMaster启动后根据本次job的描述信息，</span><br><span class="line"> 计算出需要的maptask实例数量，然后向集群申请机器启动相应数量的maptask进程</span><br><span class="line">2.maptask进程启动之后，根据给定的数据切片范围进行数据处理，主体流程为：</span><br><span class="line">  a.利用客户指定的inputformat来获取RecordReader读取数据，形成输入KV对，</span><br><span class="line">  b.将输入KV对传递给客户定义的map()方法，做逻辑运算，并将map()方法输出的KV对收集到缓存</span><br><span class="line">  c.将缓存中的KV对按照K分区排序后不断溢写到磁盘文件</span><br><span class="line">3. MRAppMaster监控到所有maptask进程任务完成之后，会根据客户指定的参数启动相应数量的reducetask进程，</span><br><span class="line"> 并告知reducetask进程要处理的数据范围（数据分区）</span><br><span class="line">4.Reducetask进程启动之后，根据MRAppMaster告知的待处理数据所在位置，从若干台maptask运行所在机器上获</span><br><span class="line"> 取到若干个maptask输出结果文件，并在本地进行重新归并排序，然后按照相同key的KV为一个组，调用客户定义的</span><br><span class="line"> reduce()方法进行逻辑运算，并收集运算输出的结果KV，然后调用客户指定的outputformat将结果数据输出到外部存储</span><br></pre></td></tr></table></figure>



<h5 id="MapReduce中的序列化"><a href="#MapReduce中的序列化" class="headerlink" title="MapReduce中的序列化"></a>MapReduce中的序列化</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">序列化：将结构化对象转换成字节流以便于进行网络传输或写入持久存储的过程。</span><br><span class="line">反序列化：将字节流转换为一系列结构化对象的过程。</span><br><span class="line">序列化作用：	</span><br><span class="line">	1、作为一种持久化格式。 </span><br><span class="line">	2、作为一种通信的数据格式。 </span><br><span class="line">	3、作为一种数据拷贝、克隆机制。</span><br><span class="line">	</span><br><span class="line">MR序列化与java序列化</span><br><span class="line">	Java 的序列化是一个重量级序列化框架(Serializable)，一个对象被序列化后，会附带很多额外的信息</span><br><span class="line">	(各种校验信息，header，继承体系等)，不便于在网络中高效传输</span><br><span class="line">	Hadoop 自己开发了一 套序列化机制(参与序列化的对象的类都要实现 Writable 接口)，精简，高效</span><br><span class="line"></span><br><span class="line">需要将自定义的 bean 作为 key，则要实现 WritableComparable 接口，因为 Writerable 接口不具 备比较功能，而 MapReduce 框中的 shuffle 过程一定会对 key 进行排序，所以还需要指定排序规则</span><br><span class="line">如果自定义的 bean 只是作为 value，那么只需要实现 Writable 接口即可</span><br><span class="line"></span><br><span class="line">总结：</span><br><span class="line">	1、key必须实现 WritableComparable 接口 </span><br><span class="line">	2、value必须要实现 Writable 接口</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="MapReduce之Combiner"><a href="#MapReduce之Combiner" class="headerlink" title="MapReduce之Combiner"></a>MapReduce之Combiner</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">作用：</span><br><span class="line">	是在 mapTask 之后 给mapTask 的结果进行局部汇总，是一个本地化的reduce操作，主要是在 mapTask 计算得到结果文件 </span><br><span class="line">	前做一个简单的合并重复key值的操作以减轻 reduceTask 的计算负载，减少网络传输。</span><br><span class="line">  </span><br><span class="line">	因为Combiner 逻辑和 Reducer 是一样的所以在实现的时候直接实现Reducer接口即可</span><br><span class="line">	job.setCombinerClass(FlowSumCombine.class)</span><br><span class="line">	</span><br><span class="line">Combiner和Reducer区别？</span><br><span class="line">	1、Combiner 和Reducer 的区别在于运行的位置:</span><br><span class="line">			Combiner 是在每一个MapTask所在的节点运行，每个Combiner 接收对应的 MapTask 结果进行局部汇总</span><br><span class="line">			Reducer 是接收全局所有 MapTask 的输出结果，进行最终的汇总</span><br><span class="line">	</span><br><span class="line">	2、Combiner 的输出 kv 类型应该跟 Reducer 的输入 kv 类型对应起来 Combiner 的输入 kv 类型应该跟</span><br><span class="line">  	 Mapper 的输出 kv 类型对应起来</span><br><span class="line">	3、Combiner 的使用要非常谨慎，因为 Combiner 在 MapReduce 过程中可能调用也可能不调用，可 能调一次也</span><br><span class="line">		 可能调多次，所以:Combiner使用的原则是:有或没有都不能影响业务逻辑，都不能影响 最终结果</span><br><span class="line">	4、sum 、count、avg、max、min中avg不适合做Combiner操作</span><br><span class="line">		 原因：任务分片后，每个 MapTask 保存有一定数据，如果要提前在 MapTask 上操作， 求出的是每个分区的平</span><br><span class="line">		 			均值，那么 MapTask 数据间不能有依赖关系。</span><br><span class="line">	</span><br></pre></td></tr></table></figure>

<h5 id="MapReduce中之Sort"><a href="#MapReduce中之Sort" class="headerlink" title="MapReduce中之Sort"></a>MapReduce中之Sort</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MR程序在处理数据的过程中会对数据排序(map输出的kv对传输到reduce之前，会排序)，排序的依据 是map输出的key，</span><br><span class="line">所以，我们如果要实现自己需要的排序规则，则可以考虑将排序因素放到key中，让 key实现接口:WritableComparable，</span><br><span class="line">然后重写key的compareTo方法</span><br><span class="line"></span><br><span class="line">实现自定义的bean来封装流量信息，并将bean作为map输出的key来传输</span><br></pre></td></tr></table></figure>

<h5 id="MapReduce中的Partitioner"><a href="#MapReduce中的Partitioner" class="headerlink" title="MapReduce中的Partitioner"></a>MapReduce中的Partitioner</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MR中会将map输出的kv对，按照相同key分组，然后分发给不同的reducetask默认的分区组件HashPartitioner的分发规则为:</span><br><span class="line">根据key的hashcode%reducetask 数来分发，所以:如果要按照我们自己的需求进行分组，则需要改写数据分发(分组)组件 </span><br><span class="line">Partitioner</span><br></pre></td></tr></table></figure>

<h5 id="MapReduce全局计数器（Counter）"><a href="#MapReduce全局计数器（Counter）" class="headerlink" title="MapReduce全局计数器（Counter）"></a>MapReduce全局计数器（Counter）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">计数器是用来记录job的执行进度和状态的。它的作用可以理解为日志。我们可以在程序的某个位置插 入计数器，记录数据</span><br><span class="line">或者进度的变化情况。</span><br><span class="line">MapReduce计数器为我们提供一个窗口，用于观察MapReduce Job运行期的各种细节数据。对MapReduce性能调优很有帮助，</span><br><span class="line">MapReduce性能优化的评估大部分都是基于这些Counter的数值表现出来的。</span><br><span class="line">MapReduce自带了许多默认Counter，现在我们来分析这些默认Counter的含义，方便大家观察 Job结 果，如输入的字节数、</span><br><span class="line">输出的字节数、Map端输入&#x2F;输出的字节数和条数、Reduce端的输入&#x2F;输出的字节数和条数等</span><br></pre></td></tr></table></figure>

<h5 id="MapJoin-DistributedCache应用"><a href="#MapJoin-DistributedCache应用" class="headerlink" title="MapJoin-DistributedCache应用"></a>MapJoin-DistributedCache应用</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">在各种实际业务场景中，按照某个关键字对两份数据进行连接是非常常见的。如果两份数据都比较小， 那么可以直接在内存中完成连接。如果是大数据量的呢?显然，在内存中进行连接会发生OOM。 MapReduce可以用来解决大数据量的链接</span><br><span class="line">MapReduce的Join操作主要分两类:MapJoin 和 ReduceJoin</span><br><span class="line"></span><br><span class="line">ReduceJoin:</span><br><span class="line">1、map阶段，两份数据data1和data2会被map分别读入，解析成以链接字段为key以查询字段为value 的key-value对，并标明数据来源是data1还是data2。 </span><br><span class="line">2、reduce阶段，reducetask会接收来自data1和data2的相同key的数据，在reduce端进行乘积链接， 最直接的影响是很消耗内存，导致OOM</span><br><span class="line"></span><br><span class="line">MapJoin:</span><br><span class="line">MapJoin 适用于有一份数据较小的连接情况。做法是直接把该小份数据直接全部加载到内存当中，按链接关键字建立索引。然后大份数据就作为 MapTask 的输入，对map()方法的每次输入都去内存当中直接去匹配连接。然后把连接结果按 key 输出，这种方法要使用 hadoop 中的 DistributedCache 把小份数据分布到各个计算节点，每个mapTask 执行任务的节点都需要加载该数据到内存，并且按连接关键 字建立索引</span><br></pre></td></tr></table></figure>

<h5 id="MapperReduce之自定义OutputFormat–数据分类输出"><a href="#MapperReduce之自定义OutputFormat–数据分类输出" class="headerlink" title="MapperReduce之自定义OutputFormat–数据分类输出"></a>MapperReduce之自定义OutputFormat–数据分类输出</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">程序的关键点是要在一个MapReduce程序中根据数据的不同输出两类结果到不同目录，这类灵活的输</span><br><span class="line">出需求可以通过自定义OutputFormat来实现。</span><br></pre></td></tr></table></figure>

<h5 id="MapperReduce之自定义InputForma–小文件合并"><a href="#MapperReduce之自定义InputForma–小文件合并" class="headerlink" title="MapperReduce之自定义InputForma–小文件合并"></a>MapperReduce之自定义InputForma–小文件合并</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1、在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS </span><br><span class="line">2、在业务处理之前，在HDFS上使用MapReduce程序对小文件进行合并 </span><br><span class="line">3、在MapReduce处理时，可采用CombineFileInputFormat提高效率</span><br><span class="line"></span><br><span class="line">第二种方式使用 MapReduce 程序来对小文件进行合并</span><br><span class="line">	1、编写自定义的InputFormat </span><br><span class="line">	2、改写RecordReader，实现一次mapTask读取一个小文件的完整内容封装了一个KV对 </span><br><span class="line">	3、在Driver类中一定要设置使用自定义的InputFormat: 		</span><br><span class="line">	job.setInputFormatClass(WholeFileInputFormat.class)</span><br></pre></td></tr></table></figure>

<h5 id="MapperReduce中map个数以及reduce的个数"><a href="#MapperReduce中map个数以及reduce的个数" class="headerlink" title="MapperReduce中map个数以及reduce的个数"></a>MapperReduce中map个数以及reduce的个数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1、mapTask到底多少个？</span><br><span class="line">	默认情况下： 这个程序的输入数据， 总共有多少个数据块，就会启动多少个MapTask</span><br><span class="line">	容错方案非常简单： 如果某个任务执行失败，会在另外一个副本所在节点启动任务继续执行</span><br><span class="line">		分布式计算应用程序</span><br><span class="line">			主管程序：MRAppMaster（跟踪，监控，协调，调度这些 task 运行）</span><br><span class="line">			小任务程序；MapTask ReduceTask</span><br><span class="line"></span><br><span class="line">	mapper阶段有很多task,执行最慢的那个task决定了mapper阶段需要多长时间完成</span><br><span class="line"></span><br><span class="line">2、reduceTask到底多少个数？</span><br><span class="line"></span><br><span class="line">	更简单： 一句代码决定到底有多少个task</span><br><span class="line">	job.setNumReduceTasks(number);</span><br><span class="line">	1、第一种情况：number &#x3D; 0</span><br><span class="line">		表示没有rducer阶段，只有mapper阶段。业务没有聚合操作，只有映射操作</span><br><span class="line">	2、第二种情况：number &#x3D; 1</span><br><span class="line">		最终的汇总，就只执行一个 reduceTask 任务能实现全局排序。而且如果你的业务需求想要实现全局排序，</span><br><span class="line">		那就必须设置reduceTask为一个</span><br><span class="line">	3、第三种情况：&gt;1</span><br><span class="line">		如果设置到 number &gt; 1 那么是没法实现全局排序每个renduceTask之间的数据执行汇总计算的时候，没有相关性。</span><br></pre></td></tr></table></figure>

<h5 id="简要概述Hadoop安装步骤"><a href="#简要概述Hadoop安装步骤" class="headerlink" title="简要概述Hadoop安装步骤"></a>简要概述Hadoop安装步骤</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1. 修改Host主机名。</span><br><span class="line">2. 配置SSH免密码登录。</span><br><span class="line">3. 关闭防火墙。</span><br><span class="line">4. 安装JDK。</span><br><span class="line">5. 上传解压Hadoop安装包。</span><br><span class="line">6. 配置Hadoop的核心配置文件hadoop-evn.sh，core-site.xml，mapred-site.xml，hdfs-site.xml，yarn-site.xml</span><br><span class="line">7. 配置hadoop环境变量</span><br><span class="line">8. 格式化hdfs # bin&#x2F;hadoop  namenode  -format</span><br><span class="line">9. 启动节点start-all.sh</span><br></pre></td></tr></table></figure>

<h5 id="如果DataNode宕机了如何恢复"><a href="#如果DataNode宕机了如何恢复" class="headerlink" title="如果DataNode宕机了如何恢复"></a>如果DataNode宕机了如何恢复</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果是短暂的宕机，可以实现写好脚本监控，将它启动起来。如果是长时间宕机了。删除他的所有数据文件和状态文件，重新启动。</span><br></pre></td></tr></table></figure>

<h5 id="如有Namenode宕机如何恢复"><a href="#如有Namenode宕机如何恢复" class="headerlink" title="如有Namenode宕机如何恢复"></a>如有Namenode宕机如何恢复</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果只是节点挂了，重启即可，如果是机器挂了，重启机器后看节点是否能重启，不能重启就要找到因修复了</span><br></pre></td></tr></table></figure>

<h5 id="Namenode内存元数据"><a href="#Namenode内存元数据" class="headerlink" title="Namenode内存元数据"></a>Namenode内存元数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">元数据：描述数据的数据</span><br><span class="line"> eg. 一个文件叫什么名字，存储在HDFS的那个目录，由几个数据块组成，每个数据多有多少个副本快以及这些副本快</span><br><span class="line">   都分别存储在了那些服务器节点中. 这些数据就是元数据</span><br><span class="line"> </span><br><span class="line"> a.内存元数据包括:</span><br><span class="line">  1、目录树结构FileSystem </span><br><span class="line">  2、文件File与切块Block之间的映射关系数据 </span><br><span class="line">  3、每个切块Block的服务器server存储列表数据</span><br><span class="line"> b.磁盘元数据包括: fsimage</span><br><span class="line">  1、目录树结构</span><br><span class="line">  2、文件与切块之间的映射关系数据</span><br><span class="line">  3、文件的各个 block 的存储管理由 DataNode 节点承担。</span><br><span class="line">   DataNode 是 HDFS 集群从节点，每一个 block 都可以在多个 DataNode 上存储多个副本</span><br><span class="line">   (副本数量也可以通过参数设置 dfs.replication，默认是3)</span><br><span class="line"> c.操作操作日志文件：editlog</span><br><span class="line"> </span><br><span class="line"> 4、HDFS 是设计成适应一次写入，多次读出的场景，且不支持文件的随机修改，支持追加</span><br><span class="line">  PS:适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太 高</span><br></pre></td></tr></table></figure>

<h5 id="Mapreduce如何解决数据倾斜"><a href="#Mapreduce如何解决数据倾斜" class="headerlink" title="Mapreduce如何解决数据倾斜"></a>Mapreduce如何解决数据倾斜</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">数据倾斜：map &#x2F;reduce程序执行时，reduce节点大部分执行完毕，但是有一个或者几个reduce节点运行很慢，导致整个程序</span><br><span class="line">的处理时间很长，这是因为某一个key的条数过多造成），这条key所在的reduce节点所处理的数据量比其他节点就大很多，从</span><br><span class="line">而导致某几个节点迟迟运行不完，此称之为数据倾斜。</span><br><span class="line"></span><br><span class="line">（1）局部聚合加全局聚合。</span><br><span class="line">第一次在 map 阶段对那些导致了数据倾斜的 key 加上 1 到 n 的随机前缀，这样本来相同的 key 也会被分到多个 Reducer </span><br><span class="line"> 中进行局部聚合，数量就会大大降低。</span><br><span class="line">第二次 mapreduce，去掉 key 的随机前缀，进行全局聚合。</span><br><span class="line"></span><br><span class="line">思想：二次 mr，第一次将 key 随机散列到不同 reducer 进行处理达到负载均衡目的。第二次再根据去掉 key 的随机前缀，</span><br><span class="line">按原 key 进行 reduce 处理。这个方法进行两次 mapreduce，性能稍差。</span><br><span class="line"></span><br><span class="line">（2）增加 Reducer，提升并行度</span><br><span class="line">JobConf.setNumReduceTasks(int)</span><br><span class="line"></span><br><span class="line">（3）实现自定义分区</span><br><span class="line">根据数据分布情况，自定义散列函数，将 key 均匀分配到不同 Reducer</span><br></pre></td></tr></table></figure>

<h5 id="Mapreduce的shuffle阶段"><a href="#Mapreduce的shuffle阶段" class="headerlink" title="Mapreduce的shuffle阶段"></a>Mapreduce的shuffle阶段</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="Yarn资源调度流程"><a href="#Yarn资源调度流程" class="headerlink" title="Yarn资源调度流程"></a>Yarn资源调度流程</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="知识点Hive"><a href="#知识点Hive" class="headerlink" title="知识点Hive"></a>知识点Hive</h4><h5 id="Hive的架构"><a href="#Hive的架构" class="headerlink" title="Hive的架构"></a>Hive的架构</h5><p><img src="/images/img/hivestructure.png"></p>
<h5 id="Hive与数据库比较"><a href="#Hive与数据库比较" class="headerlink" title="Hive与数据库比较"></a>Hive与数据库比较</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）存储位置：Hive中数据存储在HDFS，数据库中数据存储在本地文件系统</span><br><span class="line">2）数据更新：Hive中数据一般都是一次写入多次读取，数据库中的数据通常是需要经常进行修改的</span><br><span class="line">3）执行延迟：数据规模较小，Hive 执行延迟较高。数据库的执行延迟较低。当数据规模大到超过数据库的处理能力，</span><br><span class="line"> Hive的并行计算显然能体现出优势。</span><br><span class="line">4）数据规模：数据规模较小</span><br></pre></td></tr></table></figure>

<h5 id="Hive内部表和外部表"><a href="#Hive内部表和外部表" class="headerlink" title="Hive内部表和外部表"></a>Hive内部表和外部表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1）管理表：当我们删除一个管理表时，Hive也会删除这个表中数据。管理表不适合和其他工具共享数据。</span><br><span class="line">2）外部表：删除该表并不会删除掉原始数据，删除的是表的元数据</span><br></pre></td></tr></table></figure>

<h5 id="Hive四个By的区别"><a href="#Hive四个By的区别" class="headerlink" title="Hive四个By的区别"></a>Hive四个By的区别</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1）Sort By：分区内有序</span><br><span class="line">2）Order By：全局排序，只有一个Reducer；</span><br><span class="line">3）Distrbute By：类似MR中Partition，进行分区，结合sort by使用。</span><br><span class="line">4）Cluster By：当Distribute by和Sorts by字段相同时，可以使用Cluster by方式。</span><br><span class="line"> Cluster by除了具有Distribute by的功能外还兼具Sort by的功能。但是排序只能是升序排序，不能指定排序规则为ASC或者DESC。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">RANK() 排序相同时会重复，总数不会变</span><br><span class="line">DENSE_RANK() 排序相同时会重复，总数会减少</span><br><span class="line">ROW_NUMBER() 会根据顺序计算</span><br><span class="line"></span><br><span class="line">1）OVER()：指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变而变化</span><br><span class="line">2）CURRENT ROW：当前行</span><br><span class="line">3）n PRECEDING：往前n行数据</span><br><span class="line">4）n FOLLOWING：往后n行数据</span><br><span class="line">5）UNBOUNDED：起点，UNBOUNDED PRECEDING 表示从前面的起点， UNBOUNDED FOLLOWING表示到后面的终点</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="自定义UDF"><a href="#自定义UDF" class="headerlink" title="自定义UDF"></a>自定义UDF</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">在项目中是否自定义过UDF、UDTF函数，以及用他们处理了什么问题，及自定义步骤？</span><br><span class="line">1）自定义过。</span><br><span class="line">2）用UDF函数格式化过滤，筛选 日期、身份证等等</span><br><span class="line">自定义UDF步骤：继承UDF，重写evaluate方法</span><br><span class="line">自定义UDTF：继承自GenericUDTF，重写3个方法：</span><br><span class="line">	initialize(自定义输出的列名和类型)，</span><br><span class="line">	process（将结果返回forward(result)），</span><br><span class="line">	close</span><br><span class="line">为什么要自定义UDF&#x2F;UDTF，简化sql，方便调试。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="Hive的优化"><a href="#Hive的优化" class="headerlink" title="Hive的优化"></a>Hive的优化</h5><h6 id="参数优化"><a href="#参数优化" class="headerlink" title="参数优化"></a>参数优化</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1.合理设置map task和reduce task的个数</span><br><span class="line">2.数据量较大的情况下慎用count(distinct)，count(distinct)容易产生倾斜问题</span><br><span class="line">3.如果小文件很多，会影响hive的效率，合并小文件</span><br><span class="line"></span><br><span class="line">Reduce个数并不是越多越好</span><br><span class="line">（1）过多的启动和初始化Reduce也会消耗时间和资源；</span><br><span class="line">（2）有多少个Reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，</span><br><span class="line"> 则也会出现小文件过多的问题</span><br><span class="line">原则：处理大数据量利用合适的Reduce数；使单个Reduce任务处理数据量大小要合适</span><br><span class="line"></span><br><span class="line">是不是map数越多越好？</span><br><span class="line">（1）如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，</span><br><span class="line"> 而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</span><br><span class="line">是不是保证每个map处理接近128m的文件块，就高枕无忧了？</span><br><span class="line">（2）比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，</span><br><span class="line"> 如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="存储格式优化"><a href="#存储格式优化" class="headerlink" title="存储格式优化"></a>存储格式优化</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果数据量大可以采用分区存储</span><br></pre></td></tr></table></figure>

<h6 id="sql优化"><a href="#sql优化" class="headerlink" title="sql优化"></a>sql优化</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">（1）开启mapjoin</span><br><span class="line"> Reduce阶段完成join。容易发生数据倾斜。可以用MapJoin把小表全部加载到内存在map端进行join，避免reducer处理。</span><br><span class="line">（2）SELECT中，只拿需要的列，如果有，尽量使用分区过滤，少用SELECT *</span><br></pre></td></tr></table></figure>

<h4 id="知识点Spark"><a href="#知识点Spark" class="headerlink" title="知识点Spark"></a>知识点Spark</h4><h5 id="Spark有几种部署方式？请分别简要论述"><a href="#Spark有几种部署方式？请分别简要论述" class="headerlink" title="Spark有几种部署方式？请分别简要论述"></a>Spark有几种部署方式？请分别简要论述</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）Local:运行在一台机器上，通常是练手或者测试环境。</span><br><span class="line">2）Standalone:一个Master多个Slaves的资源调度集群，Spark任务提交给Master运行。是Spark自身的一个调度系统。</span><br><span class="line">3）Yarn: Spark客户端直接连接Yarn，不需要额外构建Spark集群。有yarn-client和yarn-cluster两种模式，</span><br><span class="line"> 主要区别在于：Driver程序的运行节点。</span><br><span class="line">4）Mesos：国内大环境比较少用。</span><br></pre></td></tr></table></figure>

<h5 id="简述Spark的架构与作业提交流程"><a href="#简述Spark的架构与作业提交流程" class="headerlink" title="简述Spark的架构与作业提交流程"></a>简述Spark的架构与作业提交流程</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="如何理解Spark中的血统概念（RDD）"><a href="#如何理解Spark中的血统概念（RDD）" class="headerlink" title="如何理解Spark中的血统概念（RDD）"></a>如何理解Spark中的血统概念（RDD）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage又根据什么决定task个数"><a href="#简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage又根据什么决定task个数" class="headerlink" title="简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage又根据什么决定task个数?"></a>简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage又根据什么决定task个数?</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Stage：根据RDD之间的依赖关系的不同将Job划分成不同的Stage，遇到一个宽依赖则划分一个Stage。</span><br><span class="line">Task：一个Stage是一个TaskSet，将Stage根据分区数划分成一个个的Task。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="请列举Spark的transformation算子"><a href="#请列举Spark的transformation算子" class="headerlink" title="请列举Spark的transformation算子"></a>请列举Spark的transformation算子</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">转换算子</span><br><span class="line">1）map（func）：返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成.</span><br><span class="line">2）mapPartitions(func)：类似于map，但独立地在RDD的每一个分片上运行</span><br><span class="line"> 假设有N个元素，有M个分区，那么map的函数的将被调用N次,而mapPartitions被调用M次,一个函数一次处理所有分区。</span><br><span class="line">聚合算子</span><br><span class="line">3）reduceByKey（func，[numTask]）：在一个(K,V)的RDD上调用，返回一个(K,V)的RDD，使用定的reduce函数，将相同key的值聚合到一起，reduce任务的个数可以通过第二个可选的参数来设置。</span><br><span class="line">4）aggregateByKey (zeroValue:U,[partitioner: Partitioner]) (seqOp: (U, V) &#x3D;&gt; U,combOp: (U, U) &#x3D;&gt; U: 在kv对的RDD中，，按key将value进行分组合并，合并时，将每个value和初始值作为seq函数的参数，进行计算，返回的结果作为一个新的kv对，然后再将结果按照key进行合并，最后将每个分组的value传递给combine函数进行计算（先将前两个value进行计算，将返回结果和下一个value传给combine函数，以此类推），将key与计算结果作为一个新的kv对输出。</span><br><span class="line"> 5）combineByKey(createCombiner: V&#x3D;&gt;C, mergeValue: (C, V) &#x3D;&gt;C, mergeCombiners: (C, C) &#x3D;&gt;C):</span><br><span class="line">对相同K，把V合并成一个集合。</span><br><span class="line">1.createCombiner: combineByKey() 会遍历分区中的所有元素，因此每个元素的键要么还没有遇到过，要么就和之前的某个元素的键相同。如果这是一个新的元素,combineByKey()会使用一个叫作createCombiner()的函数来创建那个键对应的累加器的初始值</span><br><span class="line">2.mergeValue: 如果这是一个在处理当前分区之前已经遇到的键，它会使用mergeValue()方法将该键的累加器对应的当前值与这个新的值进行合并</span><br><span class="line">3.mergeCombiners: 由于每个分区都是独立处理的， 因此对于同一个键可以有多个累加器。如果有两个或者更多的分区都有对应同一个键的累加器， 就需要使用用户提供的 mergeCombiners() 方法将各个分区的结果进行合并。</span><br></pre></td></tr></table></figure>

<h5 id="请列举Spark的action算子"><a href="#请列举Spark的action算子" class="headerlink" title="请列举Spark的action算子"></a>请列举Spark的action算子</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1）reduce：</span><br><span class="line">2）collect:</span><br><span class="line">3）first：</span><br><span class="line">4）take：</span><br><span class="line">5）aggregate：</span><br><span class="line">6）countByKey：</span><br><span class="line">7）foreach：</span><br><span class="line">8）saveAsTextFile：</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="请列举会引起Shuffle过程的Spark算子"><a href="#请列举会引起Shuffle过程的Spark算子" class="headerlink" title="请列举会引起Shuffle过程的Spark算子"></a>请列举会引起Shuffle过程的Spark算子</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reduceBykey：</span><br><span class="line">groupByKey：</span><br><span class="line">…ByKey:</span><br></pre></td></tr></table></figure>

<h5 id="简述Spark的两种核心Shuffle（HashShuffle与SortShuffle）的工作流程（包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle）"><a href="#简述Spark的两种核心Shuffle（HashShuffle与SortShuffle）的工作流程（包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle）" class="headerlink" title="简述Spark的两种核心Shuffle（HashShuffle与SortShuffle）的工作流程（包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle）"></a>简述Spark的两种核心Shuffle（HashShuffle与SortShuffle）的工作流程（包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势？"><a href="#Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势？" class="headerlink" title="Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势？"></a>Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势？</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reduceByKey：按照key进行聚合，在shuffle之前有combine（预聚合）操作，返回结果是RDD[k,v]。</span><br><span class="line">groupByKey：按照key进行分组，直接进行shuffle。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="Repartition和Coalesce关系与区别"><a href="#Repartition和Coalesce关系与区别" class="headerlink" title="Repartition和Coalesce关系与区别"></a>Repartition和Coalesce关系与区别</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1）关系：</span><br><span class="line">两者都是用来改变RDD的partition数量的，repartition底层调用的就是coalesce方法：</span><br><span class="line"> coalesce(numPartitions, shuffle &#x3D; true)</span><br><span class="line">2）区别：</span><br><span class="line">repartition一定会发生shuffle，coalesce根据传入的参数来判断是否发生shuffle</span><br><span class="line">一般情况下增大rdd的partition数量使用repartition，减少partition数量时使用coalesce</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="分别简述Spark中的缓存机制（cache和persist）与checkpoint机制，并指出两者的区别与联系"><a href="#分别简述Spark中的缓存机制（cache和persist）与checkpoint机制，并指出两者的区别与联系" class="headerlink" title="分别简述Spark中的缓存机制（cache和persist）与checkpoint机制，并指出两者的区别与联系"></a>分别简述Spark中的缓存机制（cache和persist）与checkpoint机制，并指出两者的区别与联系</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">都是做RDD持久化的</span><br><span class="line">cache:内存，不会截断血缘关系，使用计算过程中的数据缓存。</span><br><span class="line">checkpoint：磁盘，截断血缘关系，在ck之前必须没有任何任务提交才会生效，ck过程会额外提交一次任务。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="简述Spark中共享变量（广播变量和累加器）的基本原理与用途。"><a href="#简述Spark中共享变量（广播变量和累加器）的基本原理与用途。" class="headerlink" title="简述Spark中共享变量（广播变量和累加器）的基本原理与用途。"></a>简述Spark中共享变量（广播变量和累加器）的基本原理与用途。</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">累加器（accumulator）是Spark中提供的一种分布式的全局变量机制，即分布式的改变，然后聚合这些改变。</span><br><span class="line">用途：调试时对作业执行过程中的事件进行计数。</span><br><span class="line"></span><br><span class="line">广播变量用来高效分发较大的对象。</span><br><span class="line">用途：大表join小表的时候可以将小表通过广播变量发送给不同的executor</span><br><span class="line"></span><br><span class="line">共享变量出现的原因：</span><br><span class="line">通常在向 Spark 传递函数时，比如使用 map() 函数或者用 filter() 传条件时，可以使用驱动器程序中定义的变量，但</span><br><span class="line">是集群中运行的每个任务都会得到这些变量的一份新的副本，更新这些副本的值也不会影响驱动器中的对应变量。</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="Spark涉及到数据库的操作时，如何减少Spark运行中的数据库连接数"><a href="#Spark涉及到数据库的操作时，如何减少Spark运行中的数据库连接数" class="headerlink" title="Spark涉及到数据库的操作时，如何减少Spark运行中的数据库连接数"></a>Spark涉及到数据库的操作时，如何减少Spark运行中的数据库连接数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">使用foreachPartition代替foreach，在foreachPartition内获取数据库的连接。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="SparkSQL中RDD、DataFrame、DataSet三者的区别"><a href="#SparkSQL中RDD、DataFrame、DataSet三者的区别" class="headerlink" title="SparkSQL中RDD、DataFrame、DataSet三者的区别"></a>SparkSQL中RDD、DataFrame、DataSet三者的区别</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">共性：RDD、DataFrame、Dataset全都是spark平台下的分布式弹性数据集，为处理超大型数据提供便利</span><br><span class="line">区别：</span><br><span class="line">1.惰性机制：创建、转换，如map方法，不会立即执行，只有在遇到Action如foreach才会执行</span><br><span class="line">2.三者有许多共同的函数，如filter，排序等</span><br><span class="line">3.DataFrame每一行的类型固定为Row</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1）RDD</span><br><span class="line">优点:</span><br><span class="line">编译时类型安全 ，编译时就能检查出类型错误，面向对象的编程风格，直接通过类名点的方式来操作数据</span><br><span class="line">缺点:</span><br><span class="line">序列化和反序列化的性能开销 </span><br><span class="line">无论是集群间的通信, 还是IO操作都需要对对象的结构和数据进行序列化和反序列化。</span><br><span class="line">GC的性能开销，频繁的创建和销毁对象, 势必会增加GC</span><br><span class="line">2）DataFrame</span><br><span class="line">DataFrame引入了schema和off-heap</span><br><span class="line">schema : RDD每一行的数据, 结构都是一样的，这个结构就存储在schema中。 Spark通过schema就能够读懂数据, 因此在通信和IO时就只需要序列化和反序列化数据, 而结构的部分就可以省略了。</span><br><span class="line">3）DataSet</span><br><span class="line">DataSet结合了RDD和DataFrame的优点，并带来的一个新的概念Encoder。</span><br><span class="line">当序列化数据时，Encoder产生字节码与off-heap进行交互，能够达到按需访问数据的效果，而不用反序列化整个对象。Spark还没有提供自定义Encoder的API，但是未来会加入。</span><br></pre></td></tr></table></figure>

<p><img src="/images/img/rdddfds.png"></p>
<h4 id="知识点Hbase"><a href="#知识点Hbase" class="headerlink" title="知识点Hbase"></a>知识点Hbase</h4><h4 id="知识点Zookeeper"><a href="#知识点Zookeeper" class="headerlink" title="知识点Zookeeper"></a>知识点Zookeeper</h4><h5 id="ZooKeeper-底层组件之Watch监听系统"><a href="#ZooKeeper-底层组件之Watch监听系统" class="headerlink" title="ZooKeeper 底层组件之Watch监听系统"></a>ZooKeeper 底层组件之Watch监听系统</h5><p><img src="/images/img/image-20200507080745974.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">客户端注册监听它关心的目录节点，当目录节点发生变化(数据改变、节点删除、子目录节点增加删 除)时，ZooKeeper 会通知客户端。监听机制保证 ZooKeeper 保存的任何的数据的任何改变都能快速的响应到监听了该节点的应用程序。监听器的工作机制，其实是在客户端会专门创建一个监听线程，在本机的一个端口上等待ZooKeeper集群发送过来事件。</span><br><span class="line"></span><br><span class="line">监听工作原理:</span><br><span class="line"> ZooKeeper 的 Watcher 机制主要包括客户端线程、客户端 WatcherManager、 Zookeeper 服务器三部分。客户端在向 ZooKeeper 服务器注册的同时，会将 Watcher 对象存储在客户 端的 WatcherManager 当中。当 ZooKeeper 服务器触发 Watcher 事件后，会向客户端发送通知，客 户端线程从 WatcherManager 中取出对应的 Watcher 对象来执行回调逻辑。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="ZooKeeper-底层组件之典型应用场景"><a href="#ZooKeeper-底层组件之典型应用场景" class="headerlink" title="ZooKeeper 底层组件之典型应用场景"></a>ZooKeeper 底层组件之典型应用场景</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">a. 命名服务</span><br><span class="line">  ZooKeeper可以实现一套分布式全局唯一ID的分配机制</span><br><span class="line">b. 配置管理</span><br><span class="line">  程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。现在把这些 配置全部放到</span><br><span class="line">  ZooKeeper上去，保存在 ZooKeeper 的某个目录节点中，然后所有相关应用程序对 这个目录节点进行监听，</span><br><span class="line">  一旦配置信息发生变化，每个应用程序就会收到 ZooKeeper 的通知，然 后从 ZooKeeper 获取新的配置信息</span><br><span class="line">  应用到系统中就好。</span><br><span class="line">c. 集群管理</span><br><span class="line">  群管理无在乎两点:是否有机器退出和加入、选举master。</span><br><span class="line">d. 分布式锁</span><br><span class="line">  锁服务可以分为两三类</span><br><span class="line">  一个是写锁，对写加锁，保持独占，或者叫做排它锁，独占锁 </span><br><span class="line">  一个是读锁，对读加锁，可共享访问，释放锁之后才可进行事务操作，也叫共享锁 </span><br><span class="line">  一个是控制时序，叫时序锁</span><br><span class="line"> 解释：</span><br><span class="line">  1. 对于第一类，我们将 ZooKeeper 上的一个znode看作是一把锁，通过 createznode() 的方式来实</span><br><span class="line">      现。所有客户端都去创建 &#x2F;distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。 </span><br><span class="line">      用完删除掉自己创建的 &#x2F;distribute_lock 节点就释放出锁。</span><br><span class="line">  2. 对于第二类，&#x2F;distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，</span><br><span class="line">    和选 Master 一样，编号最小的获得锁，用完删除，依次有序</span><br><span class="line">队列管理</span><br><span class="line"> 两种类型的队列:</span><br><span class="line">  1、同步队列:当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 </span><br><span class="line">  2、先进先出队列:队列按照 FIFO 方式进行入队和出队操作。</span><br><span class="line"> 解释：</span><br><span class="line">  第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 </span><br><span class="line">  第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。</span><br></pre></td></tr></table></figure>

<h5 id="ZooKeeper的设计目的"><a href="#ZooKeeper的设计目的" class="headerlink" title="ZooKeeper的设计目的"></a>ZooKeeper的设计目的</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">zookeeper 以一个集群的方式对外提供协调服务，集群内部 的所有节点都保存了一份完整的数据，其中一个主节点用来做集群管理提供写数据服务，其他的从节点 用来同步数据，提供读数据服务。这些从节点必须保持和主节点的数据状态一致。</span><br><span class="line"></span><br><span class="line">数据复制的好处:</span><br><span class="line">1、容错:一个节点出错，不至于让整个集群无法提供服务 </span><br><span class="line">2、扩展性:通过增加服务器节点能提高 ZooKeeper 系统的负载能力，把负载分布到多个节点上 </span><br><span class="line">3、高性能:客户端可访问本地 ZooKeeper 节点或者访问就近的节点，依次提高用户的访问速度</span><br></pre></td></tr></table></figure>

<h5 id="ZooKeeper的设计特点"><a href="#ZooKeeper的设计特点" class="headerlink" title="ZooKeeper的设计特点"></a>ZooKeeper的设计特点</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">1. 最终一致性</span><br><span class="line">  client 不论连接到哪个 Server，展示给它都是同一个数据视图，这是 ZooKeeper 最重要的性能。</span><br><span class="line">2. 可靠性</span><br><span class="line">  具有简单、健壮、良好的性能，如果消息 message 被到一台服务器接受，那么它将被所有的服务器接受。</span><br><span class="line">3. 实时性</span><br><span class="line">  ZooKeeper 保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于</span><br><span class="line">  网络延时等原因，ZooKeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读</span><br><span class="line">  数据之前调用 sync() 接口。</span><br><span class="line">4. 等待无关(wait-free)</span><br><span class="line">  慢的或者失效的 client 不得干预快速的 client 的请求，使得每个 client 都能有效的等待。</span><br><span class="line">5. 原子性</span><br><span class="line">  更新只能成功或者失败，没有中间状态。</span><br><span class="line">6. 顺序性</span><br><span class="line">  包括全局有序和偏序两种:</span><br><span class="line">  1、全局有序:</span><br><span class="line">   如果在一台服务器上消息 a 在消息 b 前发布，则在所有 Server 上消息 a 都将在消息 b 前被发布;</span><br><span class="line">  2、偏序:</span><br><span class="line">   指如果一个消息 b 在消息 a 后被同一个发送者发布，a 必将排在 b 前面。</span><br></pre></td></tr></table></figure>

<h5 id="Zookeeper的集群角色解析"><a href="#Zookeeper的集群角色解析" class="headerlink" title="Zookeeper的集群角色解析"></a>Zookeeper的集群角色解析</h5><img src="/Users/wangfeng/Library/Application Support/typora-user-images/image-20200507082432134.png" alt="image-20200507082432134" style="zoom:50%;" />

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">集群的角色有可以有三种:leader, follower, observe</span><br></pre></td></tr></table></figure>

<h5 id="Zookeeper原理之Paxos算法"><a href="#Zookeeper原理之Paxos算法" class="headerlink" title="Zookeeper原理之Paxos算法"></a>Zookeeper原理之Paxos算法</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">分布式系统中的节点通信存在两种模型: </span><br><span class="line"> 共享内存(Shared Memory)</span><br><span class="line"> 消息传递(Messages Passing)</span><br><span class="line"></span><br><span class="line">Paxos算法是莱斯利•兰伯特(英语:Leslie Lamport)于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法。</span><br><span class="line"></span><br><span class="line">基于消息传递的节点通信缺点：</span><br><span class="line"> 基于消息传递通信模型的分布式系统，不可避免的会发生以下错误:进程可能会慢、被杀死或者重启， 消息可能会</span><br><span class="line"> 延迟、丢失、重复，在基础Paxos场景中，先不考虑可能出现消息篡改即拜占庭错误 (Byzantine failure，即</span><br><span class="line"> 虽然有可能一个消息被传递了两次，但是绝对不会出现错误的消息)的情况。</span><br><span class="line"></span><br><span class="line">Paxos算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发 生以上任何异常，都不会破坏决议一致性。</span><br><span class="line"></span><br><span class="line">Paxos算法使用一个希腊故事来描述，在Paxos中，存在三种角色，分别为</span><br><span class="line"> Proposer(提议者，用来发出提案proposal)， </span><br><span class="line"> Acceptor(接受者，可以接受或拒绝提案)， </span><br><span class="line"> Learner(学习者，学习被选定的提案，当提案被超过半数的 Acceptor接受后为被批准)。</span><br><span class="line">Paxos要解决的问题:</span><br><span class="line"> 决议(value)只有在被proposer提出后才能被批准 </span><br><span class="line"> 在一次Paxos算法的执行实例中，只批准(chose)一个value </span><br><span class="line"> learner只能获得被批准(chosen)的value</span><br><span class="line">ZooKeeper的选举算法有两种:</span><br><span class="line"> 一种是基于 Basic Paxos(Google Chubby采用)实现的，</span><br><span class="line"> 一种是基于 Fast Paxos(ZooKeeper采用)算法实现的。</span><br><span class="line"> ZooKeeper默认的选举算法为Fast Paxos，并且ZooKeeper在3.4.0版本后只保留了 FastLeaderElection 算法。</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">为了保证事务的顺序一致性，zookeeper 采用了递增的事务 id 号(zxid)来标识事务。所有的提议 (proposal)都在被提出的时候加上了 zxid。实现中 zxid 是一个 64 位的数字，它高32位是 epoch 用 来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch，标识当前属于那 个 leader 的统治时期。低 32 位用于递增计数。</span><br><span class="line"></span><br><span class="line">Basic Paxos流程:</span><br><span class="line">1、选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的 Server</span><br><span class="line">2、选举线程首先向所有Server发起一次询问(包括自己)</span><br><span class="line">3、选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的 serverid(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息 (serverid,zxid)，并将这些信息存储到当次选举的投票记录表中</span><br><span class="line">4、收到所有Server回复以后，就计算出id最大的那个Server，并将这个Server相关信息设置成下一次 要投票的Server</span><br><span class="line">5、线程将当前id最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n&#x2F;2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的 状态，否则，继续这个过程，直到leader被选举出来。</span><br><span class="line"></span><br><span class="line">总结：</span><br><span class="line"> 1、要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1 </span><br><span class="line"> 2、且存活的Server的数目不得少于n+1</span><br><span class="line"></span><br><span class="line">全新集群选主</span><br><span class="line"> 1、服务器1启动，此时只有它一台服务器启动了，它发出去的报没有任何响应，所以它的选举状态一直是LOOKING状态</span><br><span class="line">2、服务器2启动，它与最开始启动的服务器1进行通信，互相交换自己的选举结果，由于两者都没有历史数据，所以id 值较大的服务器2胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的 半数以上是3)，所以服务器1、2还是继续保持LOOKING状态</span><br><span class="line"> 3、服务器3启动，根据前面的理论分析，服务器3成为服务器1,2,3中的老大，而与上面不同的是，此时有 三台服务器(超过半数)选举了它，所以它成为了这次选举的leader</span><br><span class="line"> 4、服务器4启动，根据前面的分析，理论上服务器4应该是服务器1,2,3,4中最大的，但是由于前面已经有 半数以上的服务器选举了服务器3，所以它只能接收当小弟的命了</span><br><span class="line"> 5、服务器5启动，同4一样，当小弟</span><br><span class="line"> </span><br><span class="line">总结:zookeeper server的三种工作状态</span><br><span class="line"> LOOKING:当前Server不知道leader是谁，正在搜寻，正在选举 </span><br><span class="line"> LEADING:当前Server即为选举出来的leader，负责协调事务 </span><br><span class="line"> FOLLOWING:leader已经选举出来，当前Server与之同步，服从leader的命令</span><br><span class="line"> </span><br><span class="line">非全新集群选主</span><br><span class="line"> 1、逻辑时钟小的选举结果被忽略，重新投票 </span><br><span class="line"> 2、统一逻辑时钟后，数据version大的胜出 </span><br><span class="line"> 3、数据version相同的情况下，server id大的胜出</span><br><span class="line"> </span><br><span class="line">逻辑时钟:</span><br><span class="line"> 这个值从0开始递增，每次选举对应一个值，也就是说:如果在同一次选举中，那么这个值 应该是一致的;逻辑时钟</span><br><span class="line"> 值越大，说明这一次选举 leader 的进程更新，也就是每次选举拥有一个 zxid，投票结果只取 zxid 最新的</span><br><span class="line"> 数据 </span><br><span class="line">version:</span><br><span class="line"> 数据新的 version 就大，数据每次更新都会更新 version</span><br><span class="line">server id:</span><br><span class="line"> 就是我们配置的 myid 中的值，每个机器一个</span><br></pre></td></tr></table></figure>

<h5 id="Zookeeper原理之ZAB协议"><a href="#Zookeeper原理之ZAB协议" class="headerlink" title="Zookeeper原理之ZAB协议"></a>Zookeeper原理之ZAB协议</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ZooKeeper 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做 ZAB协议(Zookeeper Atomic BroadCast)。</span><br><span class="line"></span><br><span class="line">ZAB协议有两种模式</span><br><span class="line">崩溃恢复模式(选主)</span><br><span class="line"> 当服务启动或者在领导者崩溃后，ZAB就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和</span><br><span class="line"> leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和follower之间具有相同的系 统状态。</span><br><span class="line">原子广播模式(同步)</span><br><span class="line"> 当ZooKeeper集群选举出leader同步完状态退出恢复模式之后，便进入了原子广播模式。所有的写请求都被转</span><br><span class="line"> 发给leader，再由leader将更新proposal广播给follower</span><br><span class="line"> </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="Zookeeper原理之数据同步"><a href="#Zookeeper原理之数据同步" class="headerlink" title="Zookeeper原理之数据同步"></a>Zookeeper原理之数据同步</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">选完 leader 以后，zk就进入状态同步过程。</span><br><span class="line"> 1、leader等待server连接; </span><br><span class="line"> 2、follower连接leader，将最大的zxid发送给leader; </span><br><span class="line"> 3、leader根据follower的zxid确定同步点;</span><br><span class="line"> 4、完成同步后通知follower 已经成为uptodate状态; </span><br><span class="line"> 5、follower收到uptodate消息后，又可以重新接受client的请求进行服务了。</span><br></pre></td></tr></table></figure>

<h5 id="ZooKeeper-底层组件"><a href="#ZooKeeper-底层组件" class="headerlink" title="ZooKeeper 底层组件"></a>ZooKeeper 底层组件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">znode文件系统</span><br><span class="line">watch监听系统</span><br><span class="line"></span><br><span class="line">所以Zookeeper在hadoop中的作用？ </span><br><span class="line"> a. 帮hdfs存储一些数据 （active 和 standby  共享元数据系统）</span><br><span class="line"> b. 监控&#x2F;调节hdfs的状态 （active 挂掉 马上将standby切换成active）</span><br></pre></td></tr></table></figure>

<h5 id="ZooKeeper-底层组件之Znode文件系统"><a href="#ZooKeeper-底层组件之Znode文件系统" class="headerlink" title="ZooKeeper 底层组件之Znode文件系统"></a>ZooKeeper 底层组件之Znode文件系统</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">ZooKeeper 的命名空间就是 ZooKeeper 应用的文件系统，类似于 Linux 的文件系统，也是树状</span><br><span class="line"> 目的：可以确定每个路径都是唯一的</span><br><span class="line"> 注意：对于命名空间的操作必须都是绝对路径操作。</span><br><span class="line"> 与Linux文件系统不同的是</span><br><span class="line">  1. Linux 文件系统有目录和文件的区别，而 ZooKeeper 统一叫做 znode</span><br><span class="line">  2. 一个 znode 节点下可以包含子 znode，同时该节点也可以存储数据。 </span><br><span class="line">    znode 只适合存储非常小量的数据，不能超过1M，最好小于1K。</span><br><span class="line">  </span><br><span class="line">Znode的分类</span><br><span class="line"> 按照生命周期（节点的存活时间）可以分为:</span><br><span class="line">   短暂(ephemeral)(断开连接自己删除)</span><br><span class="line">   持久(persistent)(断开连接不删除，默认情况) </span><br><span class="line"> 按照是否自带序列编号可以分为:</span><br><span class="line">   SEQUENTIAL(带自增序列编号，由父节点维护) </span><br><span class="line">   非SEQUENTIAL(不带自增序列编号，默认情况)</span><br><span class="line"> 注意： 顺序节点为节点的一种特性，也就是，持久节点和临时节点都可以设置为顺序节点</span><br><span class="line">    这样一来，znode一共有4种类型：持久的、临时的，持久顺序的，临时顺序的。</span><br><span class="line">    每次创建顺序节点时，zk都会在路径后面自动添加上10位的数字（计数器），例如 </span><br><span class="line">    &lt; path &gt;0000000001，&lt; path &gt;0000000002，……这个计数器可以保证在同一个父节点下是唯一的。</span><br><span class="line"> </span><br><span class="line"> 四种节点详细说明：</span><br><span class="line"> 1. PERSISTENT 持久化 znode 节点，一旦创建这个 znode 节点，存储的数据不会 主动消失，除非是</span><br><span class="line">  客户端主动 delete</span><br><span class="line"> 2. PERSISTENT_SEQUENTIAL  持久自增顺序编号的 znode 节点，比如 ClientA 去 zookeeper  </span><br><span class="line">  service上建立一个znode名字叫做&#x2F;zk&#x2F;conf，指定了这种类型的节点后zk会创建 &#x2F;zk&#x2F;conf0000000000，</span><br><span class="line">  ClientB 再 去创建就是创建 &#x2F;zk&#x2F;conf0000000001，ClientC是创建&#x2F;zk&#x2F;conf0000000002，以后任意 </span><br><span class="line">  Client 来创建这个 znode 都会 得到一个比当前 zookeeper 命名空间最大 znode编号 +1 的 znode，</span><br><span class="line">  也就说任意一个 Client 去创建 znode 都是保证得到的 znode 编号是递增的，而且是唯一的 znode 节点</span><br><span class="line"> 3. EPHEMERAL 临时 znode 节点，Client 连接到 zk service 的时候会建立一个 session，之后用这个</span><br><span class="line">   zk 连接实例在该 session 期间创建该类型的 znode，一旦 Client 关闭了 zookeeper 的连接，服务器</span><br><span class="line">   就会清除 session，然后这个 session 建立的 znode 节点都会从命名空间消 失。总结就是，这个类型的</span><br><span class="line">    znode 的生命周期是和 Client 建立的 连接一样的。比如 ClientA 创建了一个EPHEMERAL的&#x2F;zk&#x2F;conf</span><br><span class="line">    的 znode 节点，一旦 ClientA 的 zookeeper 连接关闭，这个 znode 节点就会消失。整个zookeeper</span><br><span class="line">    service命名空间里就会删 除这个znode节点</span><br><span class="line"> 4. EPHEMERAL_SEQUENTIAL 临时自增顺序编号节点znode节点编号会自动增加但是会随session消失而消失</span><br><span class="line"> </span><br><span class="line"> https:&#x2F;&#x2F;blog.csdn.net&#x2F;lihao21&#x2F;article&#x2F;details&#x2F;51810395    </span><br></pre></td></tr></table></figure>

<h4 id=""><a href="#" class="headerlink" title=""></a></h4><p>总结**</p>
<p> 利用多个节点共同协作完成一项或多项具体业务功能的系统就是分布式系统。</p>
<pre><code>1. 系统由物理上不同分布的多个机器节点组成

   2. 系统的多个节点通过网络进行通信,协调彼此之间的工作
   3. 系统作为整体统一对外提供服务,其分布式细节对客户端透明</code></pre>
<hr>
<p>课堂笔记</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">map方法每调用一次，相当于一行操作一次</span><br><span class="line"></span><br><span class="line">reduce方法每调用一次，相当于每组进行操作一次</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">如果一行数据被分到2个块中，maptask会读取第二个快的数据，知道读取到换行符为止</span><br><span class="line"></span><br><span class="line">maptask 内存配置 1-2G（mr基于磁盘，需要内存不会很大）</span><br><span class="line">sparktask 内存配置5-10G （sparktask基于内存，给大一点内存）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">reduce task 到底多少个</span><br><span class="line"> job.setNumReduceTask(number)</span><br><span class="line"> </span><br><span class="line"> number</span><br><span class="line">  0: 没有reducer阶段,只有mapper阶段（业务没有聚合操作，只有映射阶段）</span><br><span class="line">  1: 只有一个reducetask,可以实现全局排序</span><br><span class="line">  &gt;1: 如果设置num &gt; 1 无法实现全局排序</span><br><span class="line">   每个reducetask之间的数据执行汇总计算的时候没有相关性</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">  </span><br><span class="line">shuffle过程中只能根据key排序，如果想要根据value排序，需要自定义类，把这个类当作mr程序的key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">reduce和shuffle是同时存在的，如果有reduce阶段一定有shuffle阶段</span><br><span class="line">   </span><br><span class="line">有没有这种情况</span><br><span class="line"> 有mapper阶段和reduce阶段，但是没有shuffle阶段，如果有这种情况，这种情况下是否有排序阶段</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">reduce有几个reducetask，那么输出就有几个文件，，如果全局有序一定是一个reducetask</span><br><span class="line"></span><br><span class="line">如果数据量太大怎么实现全局有序？怎么做？ 海量数据全局有序（使用多个reducetask）</span><br><span class="line"></span><br><span class="line">job设置reducetask数和分区数保持一致</span><br><span class="line">自定义分区一般自己是知道分区的个数的</span><br><span class="line"></span><br><span class="line">mapreduce程序的partition是在map阶段进行分区的</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">MR练习</span><br><span class="line">1. WordCount</span><br><span class="line">2. FlowSum</span><br><span class="line">3. FlowCombine</span><br><span class="line">4. FlowSort</span><br><span class="line">5. FlowPartition</span><br><span class="line">6. 多JOB串联</span><br><span class="line">7. day1题目--求学生成绩--普通版.txt</span><br><span class="line">8. day1题目--求学生平均成绩.txt</span><br><span class="line">9. day1题目--数据去重.txt</span><br><span class="line">10. day2题目--求访问最频繁的表.txt</span><br><span class="line">11. day2题目--求共同好友.txt</span><br><span class="line">12. day2题目--求互粉好友对.txt</span><br><span class="line">13. day2题目--数组排序并加序号.txt</span><br><span class="line">14. day2题目--versions变动版本.txt</span><br><span class="line">15. day3题目--求学生成绩--增强版.txt</span><br><span class="line"></span><br><span class="line">TopN的两种实现</span><br><span class="line"> 1. 使用2个MR</span><br><span class="line">   a. 第一个MR 分区保存数据，且分区内是有序的 </span><br><span class="line">   b. 第二个MR 读取第一个MR中每个分区的数据取TopN</span><br><span class="line"> 2. 使用1个MR</span><br><span class="line">   a. 需要自定义分组规则</span><br><span class="line">   </span><br><span class="line">eg. 统计每门课程参考学生的平均分，并且按课程存入不同的结果文件，要求一门课程一个结果文件，并且按平均分从高到低排序，分数保留一位小数</span><br><span class="line"> 必须按照课程先排序，如果不按照课程排序，那么相同课程的的信息就不会放到一起，此时就没法按照该课程的所有的平均分进行排序（默认compareTo默认是排序规则，同时也是默认的分组规则）</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p>准备好新加的节点，分发hadoop安装包，启动进程即可（不推荐，会造成数据倾斜）</p>
<p>MR程序日志问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> 如果是local模式下，控制台会输出System.out.println(&quot;&quot;)的日志</span><br><span class="line">​ 如果是集群模式下，控制台不会输出System.out.println(&quot;&quot;)日志，需要到hadoop的配置的log目录去找或者从yarn的界面点进去查看日志</span><br><span class="line">原因； 分布式集群下，MR程序会被发送到不同的节点运行，所以日志会在相应的节点输出，但是不会客户端（提交代码的节点）打印</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>Hive创建表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name            -- 小括号表示有 ｜ 表示或者</span><br><span class="line">  [COMMENT database_comment]</span><br><span class="line">  [LOCATION hdfs_path]</span><br><span class="line">  [MANAGEDLOCATION hdfs_path]</span><br><span class="line">  [WITH DBPROPERTIES (property_name&#x3D;property_value, ...)];</span><br><span class="line">  </span><br><span class="line">  -- ｜ 配合使用： (DATABASE|SCHEMA)有其中之一</span><br><span class="line">  </span><br><span class="line">  desc formatted movie; 查看表的元数据信息</span><br><span class="line">  show create table movie; 查看表的建表信息</span><br></pre></td></tr></table></figure>




    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag"># 面试</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item"></div>
      <div class="post-nav-item">
    <a href="/uncategorized/2020/10/22/hello-world.html" rel="next" title="Hello World">
      Hello World <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9C%80%E6%B1%82"><span class="nav-number">1.</span> <span class="nav-text">需求</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B1%82TopN"><span class="nav-number">1.1.</span> <span class="nav-text">求TopN</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B1%82%E4%BA%A4%E9%9B%86"><span class="nav-number">1.2.</span> <span class="nav-text">求交集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%A4%E6%96%AD%E5%85%83%E7%B4%A0%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8"><span class="nav-number">1.3.</span> <span class="nav-text">判断元素是否存在</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%9D%E8%80%83%EF%BC%9A%E4%BD%BF%E7%94%A8Hadoop-java-api"><span class="nav-number">1.4.</span> <span class="nav-text">思考：使用Hadoop java api</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9-Hadoop"><span class="nav-number">2.</span> <span class="nav-text">知识点 Hadoop</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Hadoop%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">2.1.</span> <span class="nav-text">Hadoop是什么?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%9A%84%E6%9E%B6%E6%9E%84"><span class="nav-number">2.2.</span> <span class="nav-text">分布式集群的架构</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="nav-number">2.3.</span> <span class="nav-text">HDFS的设计思想</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E6%95%88%EF%BC%9F"><span class="nav-number">2.4.</span> <span class="nav-text">HDFS怎么保证高效？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8"><span class="nav-number">2.5.</span> <span class="nav-text">HDFS如何保证数据安全</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99"><span class="nav-number">2.6.</span> <span class="nav-text">分布式文件系统的设计原则</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E7%9A%84%E7%BB%84%E7%BB%87%E6%9E%B6%E6%9E%84"><span class="nav-number">2.7.</span> <span class="nav-text">HDFS的组织架构</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E6%A6%82%E5%BF%B5%E5%92%8C%E7%89%B9%E6%80%A7"><span class="nav-number">2.8.</span> <span class="nav-text">HDFS概念和特性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E5%85%B3%E4%BA%8E%E5%B0%8F%E6%96%87%E4%BB%B6%E7%9A%84%E8%A7%A3%E5%86%B3"><span class="nav-number">2.9.</span> <span class="nav-text">HDFS关于小文件的解决</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%9D%97%E4%B8%A2%E5%A4%B1%E5%AF%B9%E6%95%B0%E6%8D%AE%E6%98%AF%E5%90%A6%E4%BC%9A%E6%9C%89%E5%BD%B1%E5%93%8D"><span class="nav-number">2.10.</span> <span class="nav-text">HDFS文件块丢失对数据是否会有影响</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">2.11.</span> <span class="nav-text">HDFS优缺点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E4%B9%8B%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6"><span class="nav-number">2.12.</span> <span class="nav-text">HDFS核心设计之架构与心跳机制</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E4%B9%8BHDFS%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.13.</span> <span class="nav-text">HDFS核心设计之HDFS安全模式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E4%B9%8BHDFS%E5%89%AF%E6%9C%AC%E5%AD%98%E6%94%BE%E7%AD%96%E7%95%A5"><span class="nav-number">2.14.</span> <span class="nav-text">HDFS核心设计之HDFS副本存放策略</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E4%B9%8BHDFS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1"><span class="nav-number">2.15.</span> <span class="nav-text">HDFS核心设计之HDFS负载均衡</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E4%B9%8B%E6%A6%82%E8%BF%B0"><span class="nav-number">2.16.</span> <span class="nav-text">HDFS工作机制之概述</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E4%B9%8B%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="nav-number">2.17.</span> <span class="nav-text">HDFS工作机制之写数据流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HDFS%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E4%B9%8B%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="nav-number">2.18.</span> <span class="nav-text">HDFS工作机制之读数据流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E4%B9%8B%E8%81%8C%E8%B4%A3"><span class="nav-number">2.19.</span> <span class="nav-text">NameNode工作机制之职责</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E4%B9%8B%E5%85%83%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6"><span class="nav-number">2.20.</span> <span class="nav-text">NameNode工作机制之元数据存储机制</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E4%B9%8BCheckPoint%E8%AF%A6%E7%BB%86%E8%BF%87%E7%A8%8B%E5%9B%BE%E8%A7%A3"><span class="nav-number">2.21.</span> <span class="nav-text">NameNode工作机制之CheckPoint详细过程图解:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#DataNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E4%B9%8B%E5%B7%A5%E4%BD%9C%E8%81%8C%E8%B4%A3"><span class="nav-number">2.22.</span> <span class="nav-text">DataNode工作机制之工作职责</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SecondaryNamenode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">2.23.</span> <span class="nav-text">SecondaryNamenode工作机制</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Hadoop%E9%AB%98%E5%8F%AF%E7%94%A8HA"><span class="nav-number">2.24.</span> <span class="nav-text">Hadoop高可用HA</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Client-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">2.25.</span> <span class="nav-text">Client 工作机制</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%85%B3%E4%BA%8EMapperReduce%E6%89%A7%E8%A1%8C%E6%9C%BA%E5%88%B6-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="nav-number">2.26.</span> <span class="nav-text">关于MapperReduce执行机制&#x2F;执行流程</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%8C%89%E7%85%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B%E6%9D%A5%E8%AF%B4"><span class="nav-number">2.26.1.</span> <span class="nav-text">按照数据处理过程来说</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%8C%89%E7%85%A7%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B%E4%B8%ADmapperreduce%E5%8F%82%E4%B8%8E%E7%9A%84api%E6%9D%A5%E8%AF%B4"><span class="nav-number">2.26.2.</span> <span class="nav-text">按照处理过程中mapperreduce参与的api来说</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce%E4%B8%AD%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96"><span class="nav-number">2.27.</span> <span class="nav-text">MapReduce中的序列化</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce%E4%B9%8BCombiner"><span class="nav-number">2.28.</span> <span class="nav-text">MapReduce之Combiner</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce%E4%B8%AD%E4%B9%8BSort"><span class="nav-number">2.29.</span> <span class="nav-text">MapReduce中之Sort</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce%E4%B8%AD%E7%9A%84Partitioner"><span class="nav-number">2.30.</span> <span class="nav-text">MapReduce中的Partitioner</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce%E5%85%A8%E5%B1%80%E8%AE%A1%E6%95%B0%E5%99%A8%EF%BC%88Counter%EF%BC%89"><span class="nav-number">2.31.</span> <span class="nav-text">MapReduce全局计数器（Counter）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapJoin-DistributedCache%E5%BA%94%E7%94%A8"><span class="nav-number">2.32.</span> <span class="nav-text">MapJoin-DistributedCache应用</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapperReduce%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89OutputFormat%E2%80%93%E6%95%B0%E6%8D%AE%E5%88%86%E7%B1%BB%E8%BE%93%E5%87%BA"><span class="nav-number">2.33.</span> <span class="nav-text">MapperReduce之自定义OutputFormat–数据分类输出</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapperReduce%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89InputForma%E2%80%93%E5%B0%8F%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6"><span class="nav-number">2.34.</span> <span class="nav-text">MapperReduce之自定义InputForma–小文件合并</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapperReduce%E4%B8%ADmap%E4%B8%AA%E6%95%B0%E4%BB%A5%E5%8F%8Areduce%E7%9A%84%E4%B8%AA%E6%95%B0"><span class="nav-number">2.35.</span> <span class="nav-text">MapperReduce中map个数以及reduce的个数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%80%E8%A6%81%E6%A6%82%E8%BF%B0Hadoop%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4"><span class="nav-number">2.36.</span> <span class="nav-text">简要概述Hadoop安装步骤</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A6%82%E6%9E%9CDataNode%E5%AE%95%E6%9C%BA%E4%BA%86%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D"><span class="nav-number">2.37.</span> <span class="nav-text">如果DataNode宕机了如何恢复</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A6%82%E6%9C%89Namenode%E5%AE%95%E6%9C%BA%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D"><span class="nav-number">2.38.</span> <span class="nav-text">如有Namenode宕机如何恢复</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Namenode%E5%86%85%E5%AD%98%E5%85%83%E6%95%B0%E6%8D%AE"><span class="nav-number">2.39.</span> <span class="nav-text">Namenode内存元数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Mapreduce%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="nav-number">2.40.</span> <span class="nav-text">Mapreduce如何解决数据倾斜</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Mapreduce%E7%9A%84shuffle%E9%98%B6%E6%AE%B5"><span class="nav-number">2.41.</span> <span class="nav-text">Mapreduce的shuffle阶段</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Yarn%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E6%B5%81%E7%A8%8B"><span class="nav-number">2.42.</span> <span class="nav-text">Yarn资源调度流程</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9Hive"><span class="nav-number">3.</span> <span class="nav-text">知识点Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E7%9A%84%E6%9E%B6%E6%9E%84"><span class="nav-number">3.1.</span> <span class="nav-text">Hive的架构</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AF%94%E8%BE%83"><span class="nav-number">3.2.</span> <span class="nav-text">Hive与数据库比较</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E5%86%85%E9%83%A8%E8%A1%A8%E5%92%8C%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="nav-number">3.3.</span> <span class="nav-text">Hive内部表和外部表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E5%9B%9B%E4%B8%AABy%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">3.4.</span> <span class="nav-text">Hive四个By的区别</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0"><span class="nav-number">3.5.</span> <span class="nav-text">窗口函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89UDF"><span class="nav-number">3.6.</span> <span class="nav-text">自定义UDF</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E7%9A%84%E4%BC%98%E5%8C%96"><span class="nav-number">3.7.</span> <span class="nav-text">Hive的优化</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96"><span class="nav-number">3.7.1.</span> <span class="nav-text">参数优化</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F%E4%BC%98%E5%8C%96"><span class="nav-number">3.7.2.</span> <span class="nav-text">存储格式优化</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#sql%E4%BC%98%E5%8C%96"><span class="nav-number">3.7.3.</span> <span class="nav-text">sql优化</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9Spark"><span class="nav-number">4.</span> <span class="nav-text">知识点Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Spark%E6%9C%89%E5%87%A0%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F%EF%BC%9F%E8%AF%B7%E5%88%86%E5%88%AB%E7%AE%80%E8%A6%81%E8%AE%BA%E8%BF%B0"><span class="nav-number">4.1.</span> <span class="nav-text">Spark有几种部署方式？请分别简要论述</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%80%E8%BF%B0Spark%E7%9A%84%E6%9E%B6%E6%9E%84%E4%B8%8E%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B"><span class="nav-number">4.2.</span> <span class="nav-text">简述Spark的架构与作业提交流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3Spark%E4%B8%AD%E7%9A%84%E8%A1%80%E7%BB%9F%E6%A6%82%E5%BF%B5%EF%BC%88RDD%EF%BC%89"><span class="nav-number">4.3.</span> <span class="nav-text">如何理解Spark中的血统概念（RDD）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%80%E8%BF%B0Spark%E7%9A%84%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96%EF%BC%8C%E4%BB%A5%E5%8F%8ASpark%E5%A6%82%E4%BD%95%E5%88%92%E5%88%86stage%EF%BC%8C%E6%AF%8F%E4%B8%AAstage%E5%8F%88%E6%A0%B9%E6%8D%AE%E4%BB%80%E4%B9%88%E5%86%B3%E5%AE%9Atask%E4%B8%AA%E6%95%B0"><span class="nav-number">4.4.</span> <span class="nav-text">简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage又根据什么决定task个数?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AF%B7%E5%88%97%E4%B8%BESpark%E7%9A%84transformation%E7%AE%97%E5%AD%90"><span class="nav-number">4.5.</span> <span class="nav-text">请列举Spark的transformation算子</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AF%B7%E5%88%97%E4%B8%BESpark%E7%9A%84action%E7%AE%97%E5%AD%90"><span class="nav-number">4.6.</span> <span class="nav-text">请列举Spark的action算子</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AF%B7%E5%88%97%E4%B8%BE%E4%BC%9A%E5%BC%95%E8%B5%B7Shuffle%E8%BF%87%E7%A8%8B%E7%9A%84Spark%E7%AE%97%E5%AD%90"><span class="nav-number">4.7.</span> <span class="nav-text">请列举会引起Shuffle过程的Spark算子</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%80%E8%BF%B0Spark%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A0%B8%E5%BF%83Shuffle%EF%BC%88HashShuffle%E4%B8%8ESortShuffle%EF%BC%89%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%88%E5%8C%85%E6%8B%AC%E6%9C%AA%E4%BC%98%E5%8C%96%E7%9A%84HashShuffle%E3%80%81%E4%BC%98%E5%8C%96%E7%9A%84HashShuffle%E3%80%81%E6%99%AE%E9%80%9A%E7%9A%84SortShuffle%E4%B8%8Ebypass%E7%9A%84SortShuffle%EF%BC%89"><span class="nav-number">4.8.</span> <span class="nav-text">简述Spark的两种核心Shuffle（HashShuffle与SortShuffle）的工作流程（包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Spark%E5%B8%B8%E7%94%A8%E7%AE%97%E5%AD%90reduceByKey%E4%B8%8EgroupByKey%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%8C%E5%93%AA%E4%B8%80%E7%A7%8D%E6%9B%B4%E5%85%B7%E4%BC%98%E5%8A%BF%EF%BC%9F"><span class="nav-number">4.9.</span> <span class="nav-text">Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Repartition%E5%92%8CCoalesce%E5%85%B3%E7%B3%BB%E4%B8%8E%E5%8C%BA%E5%88%AB"><span class="nav-number">4.10.</span> <span class="nav-text">Repartition和Coalesce关系与区别</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%86%E5%88%AB%E7%AE%80%E8%BF%B0Spark%E4%B8%AD%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%EF%BC%88cache%E5%92%8Cpersist%EF%BC%89%E4%B8%8Echeckpoint%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%B9%B6%E6%8C%87%E5%87%BA%E4%B8%A4%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB"><span class="nav-number">4.11.</span> <span class="nav-text">分别简述Spark中的缓存机制（cache和persist）与checkpoint机制，并指出两者的区别与联系</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%80%E8%BF%B0Spark%E4%B8%AD%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%EF%BC%88%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E5%92%8C%E7%B4%AF%E5%8A%A0%E5%99%A8%EF%BC%89%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E7%94%A8%E9%80%94%E3%80%82"><span class="nav-number">4.12.</span> <span class="nav-text">简述Spark中共享变量（广播变量和累加器）的基本原理与用途。</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Spark%E6%B6%89%E5%8F%8A%E5%88%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%93%8D%E4%BD%9C%E6%97%B6%EF%BC%8C%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91Spark%E8%BF%90%E8%A1%8C%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%95%B0"><span class="nav-number">4.13.</span> <span class="nav-text">Spark涉及到数据库的操作时，如何减少Spark运行中的数据库连接数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SparkSQL%E4%B8%ADRDD%E3%80%81DataFrame%E3%80%81DataSet%E4%B8%89%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">4.14.</span> <span class="nav-text">SparkSQL中RDD、DataFrame、DataSet三者的区别</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9Hbase"><span class="nav-number">5.</span> <span class="nav-text">知识点Hbase</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9Zookeeper"><span class="nav-number">6.</span> <span class="nav-text">知识点Zookeeper</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#ZooKeeper-%E5%BA%95%E5%B1%82%E7%BB%84%E4%BB%B6%E4%B9%8BWatch%E7%9B%91%E5%90%AC%E7%B3%BB%E7%BB%9F"><span class="nav-number">6.1.</span> <span class="nav-text">ZooKeeper 底层组件之Watch监听系统</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ZooKeeper-%E5%BA%95%E5%B1%82%E7%BB%84%E4%BB%B6%E4%B9%8B%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">6.2.</span> <span class="nav-text">ZooKeeper 底层组件之典型应用场景</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ZooKeeper%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84"><span class="nav-number">6.3.</span> <span class="nav-text">ZooKeeper的设计目的</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ZooKeeper%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%89%B9%E7%82%B9"><span class="nav-number">6.4.</span> <span class="nav-text">ZooKeeper的设计特点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2%E8%A7%A3%E6%9E%90"><span class="nav-number">6.5.</span> <span class="nav-text">Zookeeper的集群角色解析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Zookeeper%E5%8E%9F%E7%90%86%E4%B9%8BPaxos%E7%AE%97%E6%B3%95"><span class="nav-number">6.6.</span> <span class="nav-text">Zookeeper原理之Paxos算法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Zookeeper%E5%8E%9F%E7%90%86%E4%B9%8BZAB%E5%8D%8F%E8%AE%AE"><span class="nav-number">6.7.</span> <span class="nav-text">Zookeeper原理之ZAB协议</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Zookeeper%E5%8E%9F%E7%90%86%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5"><span class="nav-number">6.8.</span> <span class="nav-text">Zookeeper原理之数据同步</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ZooKeeper-%E5%BA%95%E5%B1%82%E7%BB%84%E4%BB%B6"><span class="nav-number">6.9.</span> <span class="nav-text">ZooKeeper 底层组件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ZooKeeper-%E5%BA%95%E5%B1%82%E7%BB%84%E4%BB%B6%E4%B9%8BZnode%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="nav-number">6.10.</span> <span class="nav-text">ZooKeeper 底层组件之Znode文件系统</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">7.</span> <span class="nav-text"></span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="阿峰"
      src="/logo/Jourdan.jpeg">
  <p class="site-author-name" itemprop="name">阿峰</p>
  <div class="site-description" itemprop="description">每一天都是一个开始。深呼吸，从头再来。永远不要埋怨你已经发生的事情，要么就改变它，要么就安静的接受它</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">阿峰</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
