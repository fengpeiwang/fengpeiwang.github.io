<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fengpeiwang.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="需求  如何从一个海量文件中寻找出现次数最多的10个元素？（TopN）      如何从两个大数据集中找出共同元素？（求交集）   如何设计一个高效算法判断一个元素是否存在于一个庞大集合内？（布隆过滤器）      1、求 TopN                 数据量小：先排序，然后limit 3                 数据量大：先分区&#x2F;分桶（把数据先分成多个小的组成部分），">
<meta property="og:type" content="article">
<meta property="og:title" content="Knowledge">
<meta property="og:url" content="http://fengpeiwang.github.io/uncategorized/2020/10/21/knowledge.html">
<meta property="og:site_name" content="夜猫的啼叫">
<meta property="og:description" content="需求  如何从一个海量文件中寻找出现次数最多的10个元素？（TopN）      如何从两个大数据集中找出共同元素？（求交集）   如何设计一个高效算法判断一个元素是否存在于一个庞大集合内？（布隆过滤器）      1、求 TopN                 数据量小：先排序，然后limit 3                 数据量大：先分区&#x2F;分桶（把数据先分成多个小的组成部分），">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://fengpeiwang.github.io/images/image-20200506224907986.png">
<meta property="og:image" content="http://fengpeiwang.github.io/images/image-20200506224907986.png">
<meta property="og:image" content="http://fengpeiwang.github.io/Users/wangfeng/Library/Application%20Support/typora-user-images/image-20200506224817897.png">
<meta property="og:image" content="http://fengpeiwang.github.io/Users/wangfeng/Library/Application%20Support/typora-user-images/image-20200506230144060.png">
<meta property="og:image" content="http://fengpeiwang.github.io/Users/wangfeng/Library/Application%20Support/typora-user-images/image-20200507080745974.png">
<meta property="og:image" content="http://fengpeiwang.github.io/Users/wangfeng/Library/Application%20Support/typora-user-images/image-20200507082432134.png">
<meta property="og:image" content="http://fengpeiwang.github.io/Users/wangfeng/Library/Application%20Support/typora-user-images/image-20200511080727192.png">
<meta property="og:image" content="http://fengpeiwang.github.io/Users/wangfeng/Library/Application%20Support/typora-user-images/image-20200511080756953.png">
<meta property="article:published_time" content="2020-10-21T12:00:54.000Z">
<meta property="article:modified_time" content="2020-10-22T02:14:28.728Z">
<meta property="article:author" content="阿峰">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://fengpeiwang.github.io/images/image-20200506224907986.png">

<link rel="canonical" href="http://fengpeiwang.github.io/uncategorized/2020/10/21/knowledge.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Knowledge | 夜猫的啼叫</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">夜猫的啼叫</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">喵喵喵</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fengpeiwang.github.io/uncategorized/2020/10/21/knowledge.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="阿峰">
      <meta itemprop="description" content="啦啦啦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="夜猫的啼叫">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Knowledge
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-21 20:00:54" itemprop="dateCreated datePublished" datetime="2020-10-21T20:00:54+08:00">2020-10-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-22 10:14:28" itemprop="dateModified" datetime="2020-10-22T10:14:28+08:00">2020-10-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>需求</strong></p>
<ol>
<li><p>如何从一个海量文件中寻找出现次数最多的10个元素？（TopN）    </p>
</li>
<li><p>如何从两个大数据集中找出共同元素？（求交集） </p>
</li>
<li><p>如何设计一个高效算法判断一个元素是否存在于一个庞大集合内？（布隆过滤器）</p>
</li>
</ol>
<p>   1、求 TopN<br>                 数据量小：先排序，然后limit 3<br>                 数据量大：先分区/分桶（把数据先分成多个小的组成部分），<br>                           每个小的部分都单独计算出来 N 个最大的<br>                       最终把每个小部分计算出来的 N 个最大的，做最终的汇总<br>                     如果现在有1W张扑克牌。给我找出最大的10张扑克牌<br>             分布式的计算应用程序应该要分成两个阶段：<br>             1、映射阶段； mapper<br>                 一个大文件切分成了多个小文件，可以进行并行计算<br>             2、聚合阶段： reducer<br>                 最重要得到统一的结果，必须要聚合！<br>         2、求 交集<br>             假如 文件 a 和 文件b 都特别大：<br>             现在求出共同的元素：<br>             1、采用的思路依然是分治法<br>             2、关键在于怎么分治（随机，范围，Hash散列，….）<br>                 做Hash散列（行业通用的默认做法）<br>                 a文件拆分成 10个文件：<br>                 b文件拆分成10个文件：<br>                 a1 和 b1 找共同元素就可以<br>                 a2 和 b2 找共同元素<br>                 …..</p>
<pre><code>     3、判断元素是否存在
         数据量小： java中的hashset
                    redis的set
         如果数据量很大：
             布隆过滤器（更强大的位图算法）
                 实现快速判断一个元素是否存在
                 优点：快速判断（爬虫: url判重）
                 缺点：误判</code></pre>
<ol start="4">
<li><p>使用Hadoop java api </p>
<p>1、删除某个文件夹下的所有空文件夹！（子层空文件删除之后，父层又成了空文件，情况处理）</p>
<p>2、删除某个目录下指定的某种类型的文件</p>
</li>
</ol>
<hr>
<ol>
<li><p>Hadoop是什么?Hadoop是怎么产生的? </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a. Hadoop 是 Apache 旗下的一套高可靠，高可扩展，分布式计算的开源软件平台</span><br><span class="line">b. 对海量数据进行分布式处理(存储和计算)</span><br><span class="line">c. 广义上来说，Hadoop 通常是指一个更广泛的概念--Hadoop生态圈</span><br><span class="line">d. hadoop 的组成</span><br><span class="line">	1.Common    (基础功能组件)(工具包，RPC框架)JNDI和 RPC</span><br><span class="line">	2.HDFS      (Hadoop Distributed File System分布式文件系统)</span><br><span class="line">	3.YARN      (Yet Another Resources Negotiator运算资源调度系统) </span><br><span class="line">	4.MapReduce (Map和Reduce分布式运算编程框架)</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
</li>
<li><p>集群节点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">集群：通过网络组合在一起完成一系列业务功能的服务器就是集群</span><br><span class="line">节点：集群中的每一台服务器就是一个节点</span><br></pre></td></tr></table></figure>
</li>
<li><p>负载均衡 和 反向代理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">反向代理，是把一些静态资源存储在服务器上，当用户有请求的时候，就直接返回反向代理服务器上的 资源给用户，而如果反向代理服务器上没有的资源，就转发给后面的负载均衡服务器，负载均衡服务器 再将请求分发给后端的web服务器。</span><br><span class="line">区别就是:</span><br><span class="line">	反向代理服务器是需要存储资源的，让用户更快速的接收到资源 </span><br><span class="line">	负载均衡就是，为了保证 后端web服务器的高可用，高并发，是不需要要存储资源，只需要转发用户的请求。</span><br></pre></td></tr></table></figure>
</li>
<li><p>分布式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">软件系统会划分成多个子系统或模块，各自运行在不同的机器上，子系统或模块之间通过网络通信进</span><br><span class="line">行协作，实现最终的整体功能</span><br><span class="line">比如分布式操作系统、分布式程序设计语言及其编译(解释)系统、分布式文件系统和分布式数据库系统 等。</span><br></pre></td></tr></table></figure>
</li>
<li><p>分布式集群的架构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">分布式集群的架构，一般有对等架构和主从架构，对等架构实现起来要复杂一些。</span><br><span class="line">	对等架构: 所有节点都可以对外提供服务，某一台节点宕机了，另外两台仍旧可以快速响应，几乎不受影响</span><br><span class="line">	主从架构: 主要压力在主节点，主节点对外对内都需要提供服务。</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS的设计思想</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">HDFS的设计目的： 解决海量数据的存储问题</span><br><span class="line">HDFS的设计思想：</span><br><span class="line">	1、分块存储</span><br><span class="line">		把一个大文件切分成多个小文件，每一个节点存储一部分小文件 使用一个集群来联合存储这个文件</span><br><span class="line">	2、冗余存储</span><br><span class="line">		一个数据块存储多个副本。多个副本分散存储在多个不同的节点上。提高副本数，有助于提高数据安全性</span><br><span class="line">  并为之后的运算分析提供数据存储支撑</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS怎么保证高效？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1、机架感知，保证数据块的存放有一个最高效的策略</span><br><span class="line">2、负载均衡</span><br><span class="line">3、安全模式</span><br><span class="line">4、Trash机制</span><br><span class="line">5、Archeive归档解决海量小文件存储问题</span><br><span class="line">6、执行流时数据访问</span><br><span class="line">7、执行自动副本维护</span><br></pre></td></tr></table></figure>
</li>
<li><p>分布式文件系统的设计原则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">第一，可靠（可扩展(动态伸缩)，可维护，高可用(7*24)）</span><br><span class="line">第二，高效（追求极致）</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS的组织架构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">元数据：描述数据的数据</span><br><span class="line">	eg. 一个文件叫什么名字，存储在HDFS的那个目录，由几个数据块组成，每个数据多有多少个副本快以及这些副本快</span><br><span class="line">			都分别存储在了那些服务器节点中. 这些数据就是元数据</span><br><span class="line">	</span><br><span class="line">	内存元数据包括:</span><br><span class="line">  1、目录树结构FileSystem </span><br><span class="line">  2、文件File与切块Block之间的映射关系数据 </span><br><span class="line">  3、每个切块Block的服务器server存储列表数据</span><br><span class="line">  磁盘元数据包括:</span><br><span class="line">  1、目录树结构</span><br><span class="line">  2、文件与切块之间的映射关系数据</span><br><span class="line">  3、文件的各个 block 的存储管理由 DataNode 节点承担。</span><br><span class="line">  	DataNode 是 HDFS 集群从节点，每一个 block 都可以在多个 DataNode 上存储多个副本</span><br><span class="line">  	(副本数量也可以通过参数设置 dfs.replication，默认是3)</span><br><span class="line">	4、HDFS 是设计成适应一次写入，多次读出的场景，且不支持文件的随机修改，支持追加</span><br><span class="line">		PS:适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太 高</span><br><span class="line"></span><br><span class="line">namenode主节点：  管理元数据</span><br><span class="line">	既存储在内存中，完整一份，保证安全又存储在磁盘中完整一份，提高效</span><br><span class="line"></span><br><span class="line">	磁盘；读写慢，数据安全</span><br><span class="line">	内存：读写快，但是掉电丢失数据</span><br><span class="line"></span><br><span class="line">secondarynamenode</span><br><span class="line">	作用：定期给namenode去合并磁盘元数据</span><br><span class="line">	目的：为了降低namenode的负载	</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS概念和特性</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">概念：它是一个文件系统，用于存储文件，通过统一的命名空间(类似于Linux文件系统的目录树)来 定位文件 其次，它			是分布式的，由很多服务器联合起来实现其功能，集群中的服务器都有各自清晰的角色定位。</span><br><span class="line">特性：</span><br><span class="line">	1、HDFS 中的文件在物理上是分块存储(block)，块的大小可以通过配置参数 dfs.blocksize 来规定，默认大小</span><br><span class="line">		 在 hadoop-2.x 版本中是128M，老版本 hadoop-1.x 中是64M</span><br><span class="line">	2、HDFS文件系统会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件</span><br><span class="line">		eg. hdfs:&#x2F;&#x2F;namenode:port&#x2F;dir-a&#x2F;dir-b&#x2F;dir-c&#x2F;file.data</span><br><span class="line">	3、元数据(目录树结构及文件分块位置信息)的管理由NameNode节点承担</span><br><span class="line">	</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS关于小文件的解决</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1、同种类型的小文件可以考虑合并</span><br><span class="line">2、建立成归档文件</span><br><span class="line">3、如果涉及到计算问题，那么一定要要进行自定义，让mapreduce程序按照我们的自定义逻辑是先</span><br><span class="line">默认情况下：一个HDFS的文件的数据块，就会针对性的启动一个小任务</span><br><span class="line">	说明：</span><br><span class="line">		如果每个文件都比较小，导致每个数据块都比较小好不容易启动了一个计算任务，但是计算的数据量非常的小。</span><br><span class="line">		大量的机器性能消耗在了启动任务上。</span><br><span class="line">		每个文件的切块大小：不能太大，也不能太小</span><br><span class="line">		太小：不好配合计算, 也会造成元数据太多，给namenode造成压力</span><br><span class="line">		太大：不能使数据均匀分布到整个HDFS，没法充分利用整个HDFS的性能</span><br><span class="line">	HDFS不适合存小文件的原因：</span><br><span class="line">		元信息存储在NameNode内存中，一个节点的内存是有限的 存取大量小文件消耗大量的寻道时间，类比拷贝大量小</span><br><span class="line">		文件与拷贝同等大小的一个大文件 NameNode存储block数目是有限的，一个block元信息消耗大约150 byte内</span><br><span class="line">		存，存储1亿个block，大约 需要20GB内存</span><br><span class="line">		如果一个文件大小为10K，则1亿个文件大小仅为1TB(但要消耗掉NameNode 20GB内存)</span><br><span class="line">		</span><br><span class="line">面试题：</span><br><span class="line">小文件的优化</span><br><span class="line">	1、在数据采集的时候，就将小文件或小批数据在本地合成大文件再上传HDFS(cat &#x2F;file&#x2F;* &gt;&gt; merge.txt) </span><br><span class="line">			局限： parquet不支持</span><br><span class="line">	2、在业务处理之前，在HDFS上使用MapReduce程序对小文件进行合并 （程序端）</span><br><span class="line">	3、在MapReduce处理时，可采用CombineFileInputFormat提高效率</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS文件块丢失对数据是否会有影响 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">如果丢了一个副本，这是没关系的，因为数据块有多个副本（默认是3个副本）。HDFS的内部，会有一个自动维护机制：定期汇报维护所有数据块的副本个数，是否满足客户端要求的个数。发现副本数多了，会删掉。发现副本数少了，会复制出来，始终保持对应的副本数</span><br><span class="line">	注意： 如果丢失了一个数据块的所有副本，无法恢复</span><br><span class="line">				提供副本数，可以提高数据的安全性</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS优缺点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line">	1. 构建在廉价机器上，通过多副本提高可靠性，提供了容错和恢复机制</span><br><span class="line">	2. 高容错性，数据自动保存多个副本，副本丢失后，自动恢复，增加副本，提高容错性 副本丢失，HDFS的内部机制可自动恢复。</span><br><span class="line">	3. 适合批处理，移动计算而非数据，数据位置暴露给计算框架</span><br><span class="line">	4. 适合大数据处理</span><br><span class="line">			数据规模:GB、TB、甚至PB级数据 </span><br><span class="line">			文件规模:百万规模以上的文件数量 </span><br><span class="line">			节点规模:10K+节点规模</span><br><span class="line">	5. 流式文件访问</span><br><span class="line">		一次性写入，多次读取。 保证数据一致性</span><br><span class="line">	</span><br><span class="line">移动计算而非数据相关问题</span><br><span class="line">	数据存入ＨＤＦＳ的时候， 就已经分布好了。 那么是 随便在那个节点启动一个任务，然后把数据传送过来 好呢， 还是 数据在那个节点， 就去哪个节点启动 任务 好呢？</span><br><span class="line">	数据是不动的了，那到底  程序找数据好呢，  还是 数据找程序 好呢。 数据一定会比程序 大的多， 那传送效率肯定低的多。	</span><br><span class="line">	去哪个节点启动任务这个操作是把程序发到该节点</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	你觉得  nodemanager 和 datanode 要不要 在 同一个节点都 启动？</span><br><span class="line">	</span><br><span class="line">缺点：</span><br><span class="line">	1. 低延迟数据访问 </span><br><span class="line">		 比如毫秒级</span><br><span class="line">		 低延迟与高吞吐率</span><br><span class="line">	2. 小文件存取</span><br><span class="line">		 占用 NameNode 大量内存 150b * 1000W &#x3D; 15E,1.5G </span><br><span class="line">		 寻道时间超过读取时间</span><br><span class="line">	3. 并发写入、文件随机修改 </span><br><span class="line">		 一个文件只能有一个写者 仅支持 append，不支持update</span><br><span class="line">	4. 如果副本数比较大，那么这个HDFS集群是比较消耗磁盘空间的！</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS  FileSystem实例获取</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">前提：Java中获取对象的方法</span><br><span class="line">		1. 静态工厂</span><br><span class="line">		2. 反射</span><br><span class="line">		3. new 实例化</span><br><span class="line">		4. 克隆</span><br><span class="line">		5. 序列化</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">在 Java 中操作 HDFS，首先要获得一个客户端实例:</span><br><span class="line">	Configuration conf &#x3D; new Configuration(); </span><br><span class="line">	FileSystem fs &#x3D; FileSystem.get(conf);</span><br><span class="line">我们的操作目标是 HDFS，所以获取到的 fs 对象应该是 DistributedFileSystem 的实例;</span><br><span class="line"></span><br><span class="line">get方法是从 何处判断具体实例化那种客户端类呢?</span><br><span class="line">	从conf中的一个参数 fs.defaultFS的配置值判断。</span><br><span class="line">	如果我们的代码中没有指定 fs.defaultFS，并且工程 classpath 下也没有给定相应的配置，conf 中的默 认值</span><br><span class="line">	就来自于 hadoop 的 jar 包中的 core-default.xml，默认值为:file:&#x2F;&#x2F;&#x2F;，</span><br><span class="line">	则获取的将不是一个DistributedFileSystem 的实例，而是一个本地文件系统的客户端对象 LocalFileSystem</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS javaAPI常用操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1、建立文件夹</span><br><span class="line">2、上传文件</span><br><span class="line">3、下载文件</span><br><span class="line">4、删除文件或者文件夹</span><br><span class="line">5、重命名文件或者文件夹</span><br><span class="line">6、查看目录信息，只显示该文件夹下的文件信息</span><br><span class="line">8、查看文件及文件夹信息</span><br><span class="line">9、HDFS流式数据访问</span><br><span class="line">10、经典案例</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS核心设计之心跳机制</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">1. Hadoop 中包含了两个独立的主从架构(Master &#x2F; Slave)的集群:HDFS 和 YARN </span><br><span class="line">	 HDFS的主节点的守护进程是:NameNode，从节点的守护进程是 DataNode， </span><br><span class="line">	 YARN的主节点的守护进程是:ResourceManager，从节点的守护进程是 NodeManager</span><br><span class="line">2. Master 启动的时候会启动一个 IPC(Inter-Process Comunication，进程间通信)Server服务，等待Slave </span><br><span class="line">	 的链接</span><br><span class="line">3. Slave 启动时，会主动链接 Master 的 IPC 服务，并且每隔3秒链接一次 Master，这个间隔时间是可以调整</span><br><span class="line">	 的，参数为 dfs.heartbeat.interval ，这个每隔一段时间去连接一次的机制，我们形象的 称为心跳。</span><br><span class="line">	 Slave 通过心跳汇报自己的信息给Master，Master也通过心跳给Slave下达命令</span><br><span class="line">4. NameNode 通过心跳得知 DataNode 的状态，ResourceManager 通过心跳得知 NodeManager 的状态</span><br><span class="line">5. 如果 master 长时间都没有收到 slave 的心跳，就认为该slave挂掉了。</span><br><span class="line"></span><br><span class="line">问题？Namenode感知到Datanode掉线死亡的时长计算？</span><br><span class="line">https:&#x2F;&#x2F;lihuimintu.github.io&#x2F;2019&#x2F;11&#x2F;18&#x2F;hdfs-datanode-heartbeat&#x2F;</span><br><span class="line"></span><br><span class="line">	解：HDFS 默认的超时时间为10分钟+30秒,也就是630s. 这里暂且定义超时时间为timeout计算公式为：</span><br><span class="line">		 	timeout &#x3D; 2 * heartbeat.recheck.interval + 10 * dfs.heartbeat.interval</span><br><span class="line">		默认的 heartbeat.recheck.interval 大小为5分钟， dfs.heartbeat.interval 默认的大小为3 秒。</span><br><span class="line">		注意:</span><br><span class="line">    	hdfs-site.xml 配置文件中的 heartbeat.recheck.interval 的单位为毫秒</span><br><span class="line">		eg. </span><br><span class="line">			如果heartbeat.recheck.interval设置为5000(毫秒)， </span><br><span class="line">			dfs.heartbeat.interval 设置为3(秒，默认)，总的超时时间为40s</span><br><span class="line">			</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS核心设计之HDFS安全模式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">前提：</span><br><span class="line">		首先须知 SafeMode 是 NameNode 的一种状态之一(active &#x2F; standby &#x2F; safemode 安全模式)</span><br><span class="line">问题:</span><br><span class="line"> 1. 集群启动后，可以查看目录，但是上传文件时报错，打开web页面可看到NameNode正处于SafeMode状态，</span><br><span class="line"> 		怎么处理?</span><br><span class="line"> 	  第一种情况： </span><br><span class="line"> 	  	如果是在 HDFS 集群正常冷启动时，NameNode 也会在 SafeMode 状态下维持相当长的一段时间，此时你 </span><br><span class="line"> 	  	不需要去理会，等待它自动退出安全模式即可。</span><br><span class="line"> 		第二种情况：</span><br><span class="line"> 			可以手动强制退出安全模式</span><br><span class="line"> 			</span><br><span class="line"> </span><br><span class="line"> 2. NameNode进入安全模式2种方式</span><br><span class="line"> 	a. NameNode发现集群中的 block 丢失率达到一定比例时(0.1%)，NameNode就会进入安全模式</span><br><span class="line"> 	b. 集群启动过程中会进入安全模式</span><br><span class="line"> 注意：</span><br><span class="line"> 	在安全模式下，客户端不能进行涉及元数据修改的操作，只能操作涉及元数据查询的相关操作(比 如 ls &#x2F; mkdir)</span><br><span class="line">  丢失率是可以手动配置的，默认是: </span><br><span class="line">  		(threshold : 入口；门槛；开始；极限；临界值)</span><br><span class="line">  	旧版本：dfs.safemode.threshold.pct&#x3D;0.999f</span><br><span class="line">  	新版本：dfs.namenode.safemode.threshold-pct&#x3D;0.999f</span><br><span class="line">  	</span><br><span class="line"> 3.正常启动的时候进入安全的原理:</span><br><span class="line">			1. NameNode的内存元数据中，包含文件存储目录的路径、副本数、blockid，及每一个block所在 </span><br><span class="line">				 DataNode的信息，而fsimage中，不包含block所在的DataNode信息</span><br><span class="line">			2. 当NameNode冷启动时，此时内存中的元数据只能从fsimage中加载而来，从而就没有block所在的 </span><br><span class="line">				 DataNode信息，就会导致NameNode认为所有的block都已经丢失</span><br><span class="line">			3. 从而HDFS会自动进入安全模式 </span><br><span class="line">			4. 伴随着每个DataNode启动后，会定期向NameNode汇报自身所持有的</span><br><span class="line">				 blockid信息，随着DataNode陆续启动，从而陆续汇报block信息，NameNode就会将内存元数据中的</span><br><span class="line">				 block所在DataNode信息补全更新</span><br><span class="line">			5. 当HDFS集群中的每个文件都找到了所有block的位置，从而自动退出安全模式</span><br><span class="line">		安全模式常用操作命令:</span><br><span class="line">			 hdfs dfsadmin -safemode leave &#x2F;&#x2F;强制NameNode退出安全模式  </span><br><span class="line">       hdfs dfsadmin -safemode enter &#x2F;&#x2F;进入安全模式</span><br><span class="line">       hdfs dfsadmin -safemode get   &#x2F;&#x2F;查看安全模式状态</span><br><span class="line">       hdfs dfsadmin -safemode wait  &#x2F;&#x2F;等待，一直到安全模式结束</span><br><span class="line"></span><br><span class="line">	安全模式下用户可以进行的操作(不修改元数据的操作):ls查询、cat查看文件内容、get下载 </span><br><span class="line">	安全模式下用户不可以进行的操作(修改了元数据的操作):创建目录、上传、修改文件名、文件追加</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS核心设计之HDFS副本存放策略</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">HDFS 将每一个文件的数据进行分块存储，同时每一个数据块又保存有多个副本，这些数据块副 本分布在不同的机器节点上，这种数据 分块存储+副本的策略 是 HDFS 保证可靠性和性能的关键。</span><br><span class="line">  1. 文件分块存储之后按照数据块来读，提高了文件随机读的效率和并发读的效率; </span><br><span class="line">  2. 保存数据块若干副本到不同的机器节点实现可靠性的同时也提高了同一数据块的并发读效率;</span><br><span class="line">  3. 数据分块是非常切合 MapReduce 中任务切分的思想。在这里，副本的存放策略又是 HDFS 实现高可靠性和</span><br><span class="line">     高性能的关键。</span><br><span class="line">存放策略总结：</span><br><span class="line">    如果3个副本都存在一个节点或者一个机架上，相对不安全，如果三个副本分散均匀存储在所有机架的</span><br><span class="line">    所有节点中，写入数据的代价很高。</span><br><span class="line">    兼顾安全和性能，数据既不分散放在多个机架，也不集中存 放在一个机架。</span><br><span class="line">    而是存储写入的时候，选择本地机架存储2份，其他的机架均匀存储所有数据块的第三个副本。</span><br><span class="line">    </span><br><span class="line">    存储写入的时候，选择本地机架存储2份，其他的机架均匀存储所有数据块的第三个副本 </span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS核心设计之HDFS负载均衡</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">什么情况下会造成负载？</span><br><span class="line">	1. 在进行文件上传的时候会优先选择客户端所在节点，如果习惯性使用同一个客户端会造成客户端所在节点存储的数</span><br><span class="line">		 据比较多。集群会有一个自动的负载均衡的操作，只不过这个负载均衡的操作比较慢。</span><br><span class="line">	2. 机器与机器之间磁盘利用率不平衡是HDFS集群非常容易出现的情况，例如:当集群内新增、删除节点，</span><br><span class="line">	3. 某个节点机器内硬盘存储达到饱和值。</span><br><span class="line">	4. 当数据不平衡时，Map任务可能会分配到没有存储数据的机器，这将导致网络带宽的消耗，也无法很好的</span><br><span class="line">		 进行本地计算。</span><br><span class="line"></span><br><span class="line">负载均衡导致什么情况发生？</span><br><span class="line">		当HDFS负载不均衡时，数据分布不均匀，导致热点发生。</span><br><span class="line">		</span><br><span class="line">负载均衡调整的原则：</span><br><span class="line">			数据平衡不能导致数据块减少，数据块备份丢失 </span><br><span class="line">			管理员可以中止数据平衡进程 </span><br><span class="line">			每次移动的数据量以及占用的网络资源，必须是可控的 </span><br><span class="line">			数据均衡过程，不能影响 namenode 的正常工作</span><br><span class="line">			</span><br><span class="line">如何操作？</span><br><span class="line">	在Hadoop中，包含一个 start-balancer.sh 脚本，通过运行这个工具，启动 HDFS 数据均衡服务。 </span><br><span class="line">	该工具可以做到热插拔，即无须重启计算机和 Hadoop 服务。</span><br><span class="line">      sbin&#x2F;start-balancer.sh </span><br><span class="line">      sbin&#x2F;start-balancer.sh -threshold 5 或者 sbin&#x2F;start-balancer.sh -t 10%</span><br><span class="line">      </span><br><span class="line">每个节点计算出一个磁盘容量，磁盘容量最大的和最小的差距不超过10%</span><br><span class="line">	eg. 40% ~ 50% 之间都可以</span><br><span class="line">	</span><br><span class="line">在做负载均衡的时候不能影响正常的上传和下载业务操作（HDFS集群默认不允许balance操作占用很大的网络带宽，因为自动进行均衡非常慢），如果非要做那么就需要限制带宽：</span><br><span class="line">  hdfs dfsadmin -setBalanacerBandwidth newbandwidth </span><br><span class="line">  hdfs dfsadmin -setBalanacerBandwidth 10485760</span><br><span class="line">  该数值的单位是字节，上面的配置是10M&#x2F;s，默认是1M&#x2F;s</span><br><span class="line"></span><br><span class="line">配置：</span><br><span class="line">	在hdfs-site.xml配置文件中进行设置:</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.balance.bandwidthPerSec&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;10485760&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;description&gt; Specifies the maximum bandwidth that each datanode can utilize</span><br><span class="line">                  for the balancing purpose in term of the number of bytes per second.</span><br><span class="line">    &lt;&#x2F;description&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS工作机制之概述</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1、HDFS 集群分为两大主要角色:NameNode、DataNode，还有两种辅助角色 SecondaryNamenode 和Client</span><br><span class="line">2、NameNode 负责管理整个文件系统的元数据，并且负责响应客户端的请求</span><br><span class="line">3、DataNode 负责管理用户的文件数据块，并且通过心跳机制汇报给 NameNode</span><br><span class="line">4、文件会按照固定的大小 (dfs.blocksize) 切成若干块后分布式存储在若干台 DataNode 上</span><br><span class="line">5、每一个文件块可以有多个副本，并存放在不同的DataNode上</span><br><span class="line">6、DataNode会定期向NameNode汇报自身所保存的文件block信息，而NameNode则会负责保持文件的副本数量</span><br><span class="line">7、HDFS 的内部工作机制对客户端保持透明，客户端请求访问 HDFS 都是通过向 NameNode 申请来进行</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS工作机制之写数据流程<br><img src="/images/image-20200506224907986.png"></p>
<img src="/images/image-20200506224907986.png">
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">客户端要向 HDFS 写数据，首先要跟 NameNode 通信以确认可以写文件并获得接收文件 block 的 DataNode，然后，客户端按顺序将文件逐个 block 传递给相应 DataNode，并由接收到block的DataNode负责向其他DataNode 复制 block 的副本。</span><br><span class="line">	1、使用 HDFS 提供的客户端 Client，向远程的 NameNode 发起 RPC 请求</span><br><span class="line">	2、NameNode 会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件创建 一个记录，</span><br><span class="line">		 否则会让客户端抛出异常;</span><br><span class="line">	3、当客户端开始写入文件的时候，客户端会将文件切分成多个 packets，并在内部以数据队列“data queue(数据</span><br><span class="line">		 队列)”的形式管理这些 packets，并向 NameNode 申请 blocks，获取用来存储 replicas 的合适的 </span><br><span class="line">		 DataNode 列表，列表的大小根据 NameNode 中 replication的设定而定;</span><br><span class="line">	4、开始以 pipeline(管道)的形式将 packet 写入所有的 replicas中。客户端把 packet 以流的方式写 入第</span><br><span class="line">		 一个DataNode，该 DataNode 把该 packet存储之后，再将其传递给在此 pipeline 中的下一个 </span><br><span class="line">		 DataNode，直到最后一个 DataNode，这种写数据的方式呈流水线的形式。</span><br><span class="line">	5、最后一个 DataNode 成功存储之后会返回一个 ack packet(确认队列)，在 pipeline 里传递至客户 端，</span><br><span class="line">		 在客户端的开发库内部维护着 &quot;ack queue&quot;，成功收到 DataNode 返回的ack packet后会从</span><br><span class="line">		 &quot;data queue&quot;移除相应的packet。</span><br><span class="line">	6、如果传输过程中，有某个 DataNode 出现了故障，那么当前的 pipeline 会被关闭，出现故障的 DataNode </span><br><span class="line">	 	 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 DataNode 中继续以 pipeline 的 形式传</span><br><span class="line">	 	 输，同时NameNode 会分配一个新的 DataNode，保持 replicas 设定的数量。</span><br><span class="line">	7、客户端完成数据的写入后，会对数据流调用 close() 方法，关闭数据流;</span><br><span class="line">	8、只要写入了 dfs.replication.min (最小写入成功的副本数)的复本数(默认为1)，写操作就会 成功，并且这</span><br><span class="line">		 个块可以在集群中异步复制，直到达到其目标复本数(dfs.replication 的默认值为 3)，因为 NameNode 已</span><br><span class="line">		 经知道文件由哪些块组成，所以它在返回成功前只需要等待数据块进行最小 量的复制。</span><br><span class="line">	</span><br><span class="line">5.2.2. 详细步骤</span><br><span class="line">1、客户端通过调用 DistributedFileSystem 的 create 方法，创建一个新的文件。</span><br><span class="line">2、DistributedFileSystem 通过 RPC(远程过程调用)调用 NameNode，去创建一个没有 blocks 关联 的新文</span><br><span class="line">	 件。创建前，NameNode 会做各种校验，比如文件是否存在，客户端有无权限去创建等。如果 校验通过，</span><br><span class="line">	 NameNode 就会记录下新文件，否则就会抛出IO异常。</span><br><span class="line">3、前两步结束后会返回 FSDataOutputStream 的对象，和读文件的时候相似，FSDataOutputStream 被封装成 </span><br><span class="line">	 DFSOutputStream，DFSOutputStream 可以协调 NameNode 和 DataNode。客户端开始写 数据到</span><br><span class="line">	 DFSOutputStream，DFSOutputStream 会把数据切成一个个小 packet，然后排成队列 data queue。</span><br><span class="line">4、DataStreamer 会去处理接受 data queue，它先问询 NameNode 这个新的 block 最适合存储的在 哪几个</span><br><span class="line">	 DataNode里，比如重复数是3，那么就找到3个最适合的 DataNode，把它们排成一个 pipeline。</span><br><span class="line">	 DataStreamer 把 packet 按队列输出到管道的第一个 DataNode 中，第一个 DataNode 又 把</span><br><span class="line">   packet 输出到第二个 DataNode 中，以此类推。</span><br><span class="line">5、DFSOutputStream 还有一个队列叫 ack queue，也是由 packet 组成，等待 DataNode 的收到响 应，当</span><br><span class="line">	 pipeline 中的所有 DataNode都表示已经收到的时候，这时 ack queue才会把对应的 packet 包 移除掉。</span><br><span class="line">6、客户端完成写数据后，调用 close 方法关闭写入流。</span><br><span class="line">7、DataStreamer 把剩余的包都刷到 pipeline 里，然后等待 ack 信息，收到最后一个ack 后，通知</span><br><span class="line">	 DataNode 把文件标示为已完成。</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS工作机制之读数据流程</p>
<img src="/Users/wangfeng/Library/Application Support/typora-user-images/image-20200506224817897.png" alt="image-20200506224817897" style="zoom: 25%;" />

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">客户端将要读取的文件路径发送给 NameNode，NameNode 在经过校验之后获取文件的元信息(主要 是 block 的存放位置信息)返回给客户端，客户端根据返回的信息找到相应 DataNode 逐个获取文件的 block 并在客户端本地进行数据追加合并从而获得整个文件。</span><br><span class="line">1、使用 HDFS 提供的客户端 Client，向远程的 NameNode 发起RPC请求; </span><br><span class="line">2、NameNode会视情况返回文件的全部block列表，对于每个block，NameNode都会返回有该block拷贝的DataNode</span><br><span class="line">	 地址; </span><br><span class="line">3、客户端Client会选取离客户端最近的DataNode来读取block;如果客户端本身就是DataNode，那么将从本地直接获</span><br><span class="line">	 取数据; </span><br><span class="line">4、读取完当前block的数据后，关闭当前的DataNode链接，并为读取下一个block寻找最佳的DataNode; </span><br><span class="line">5、当读完列表block后，且文件读取还没有结束，客户端会继续向NameNode获取下一批的block列表; </span><br><span class="line">6、读取完一个block都会进行checksum验证，如果读取DataNode时出现错误，客户端会通知NameNode，然后再从下</span><br><span class="line"> 	 一个拥有该block拷贝的DataNode继续读。</span><br><span class="line"></span><br><span class="line">详细文字说明</span><br><span class="line">1、客户端首先调用 FileSystem 对象的open方法打开文件，其实获取的是一个DistributedFileSystem 的实例。</span><br><span class="line">2、DistributedFileSystem 通过调用 RPC (远程过程调用)向 namenode 发起请求，获得文件的第一批 block</span><br><span class="line">	 的位置信息。同一 block 按照备份数会返回多个 DataNode 的位置信息，并根据集群的网络拓扑 结构排序，距</span><br><span class="line">	 离客户端近的排在前面， 如果客户端本身就是该 DataNode，那么它将从本地读取文件。</span><br><span class="line">3、DistributedFileSystem 类返回一个 FSDataInputStream 对象给客户端，用来读取数据，该对象会 被封装</span><br><span class="line">	 成 DFSInputStream 对象，该 DFSInputStream 对象管理着 datanode 和 namenode 的 I&#x2F;O 数 据流。</span><br><span class="line">	 客户端对输入端调用 read 方法，DFSInputStream 就会找出离客户端最近的 datanode 并连接 datanode。</span><br><span class="line">4、在数据流中重复调用 read() 函数，直到这个块全部读完为止。DFSInputStream 关闭和此 DataNode 的连接。</span><br><span class="line">	 接着读取下一个 block 块。这些操作对客户端来说是透明的，从客户端的角度来看 只是读一个持续不断的流。每</span><br><span class="line">	 读取完一个 block 都会进行 checksum 验证，如果读取 datanode 时出现 错误，客户端会通知 NameNode</span><br><span class="line">	 ，然后再从下一个拥有该 block 拷贝的 datanode 继续读。</span><br><span class="line">5、当正确读取完当前 block 的数据后，关闭当前的DataNode 链接，并为读取下一个block寻找最佳的DataNode。</span><br><span class="line">	 如果第一批 block 都读完了，且文件读取还没有结束，DFSInputStream 就会去 namenode 拿下一批 block</span><br><span class="line">   的位置信息继续读。</span><br><span class="line">6、当客户端读取完毕数据的时候，调用 FSDataInputStream 的 close 方法关闭掉所有的流。</span><br></pre></td></tr></table></figure>
</li>
<li><p>NameNode工作机制之职责</p>
<p>思考：</p>
<p>​    a. NameNode 服务器的磁盘故障导致 NameNode 宕机，如何挽救集群及数据?<br>​    b. NameNode 是否可以有多个? NameNode 内存要配置多大? NameNode 跟集群数据存储能力有关系吗?<br>​    c. 文件的 blocksize 究竟调大好还是调小好?结合 MapReduce 考量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NameNode 是 HDFS 的主节点，是负责管理整个 HDFS 集群的，相当于一个团队的老大。</span><br><span class="line">1、负责客户端请求(读写数据请求)的响应</span><br><span class="line">2、管理 HDFS 的元数据:包括命名空间、访问控制信息、文件与数据块的映射关系以及数据块的存储 位置</span><br><span class="line">3、配置和应用副本存放策略</span><br><span class="line">4、管理集群数据块负载均衡问题</span><br></pre></td></tr></table></figure>
</li>
<li><p>NameNode工作机制之元数据存储机制</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A、内存中有一份完整的元数据(内存metadata)</span><br><span class="line">B、磁盘有一个“准完整”的元数据镜像(fsimage)文件(在NameNode的工作目录中)</span><br><span class="line">C、用于衔接内存metadata和持久化元数据镜像fsimage之间的操作日志(edits文件)</span><br><span class="line">PS:当客户端对hdfs中的文件进行新增或者修改操作，操作记录首先被记入edits日志文件中，当客户 端操作成功后，相应的元数据会更新到内存metadata中</span><br></pre></td></tr></table></figure>
</li>
<li><p>NameNode工作机制之元数据存储机制</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">WAL(Write ahead Log): 预写日志系统</span><br><span class="line">在计算机科学中，预写式日志(Write-ahead logging，缩写 WAL)是关系数据库系统中用于提供原子 性和持久性(ACID属性中的两个)的一系列技术。在使用 WAL 的系统中，所有的修改在提交之前都要 先写入 log 文件中。</span><br><span class="line">Log 文件中通常包括 redo 和 undo 信息。这样做的目的可以通过一个例子来说明。假设一个程序在执 行某些操作的过程中机器掉电了。在重新启动时，程序可能需要知道当时执行的操作是成功了还是部分 成功或者是失败了。如果使用了 WAL，程序就可以检查 log 文件，并对突然掉电时计划执行的操作内容 跟实际上执行的操作内容进行比较。在这个比较的基础上，程序就可以决定是撤销已做的操作还是继续 完成已做的操作，或者是保持原样。</span><br><span class="line">WAL 允许用 in-place 方式更新数据库。另一种用来实现原子更新的方法是 shadow paging，它并不是 in-place 方式。用 in-place 方式做更新的主要优点是减少索引和块列表的修改。ARIES 是WAL 系列技术 常用的算法。在文件系统中，WAL 通常称为 journaling。PostgreSQL也是用 WAL 来提供 point-in- time 恢复和数据库复制特性。</span><br><span class="line"></span><br><span class="line">NameNode对数据的管理采用了两种存储形式:内存和磁盘 首先是内存中</span><br><span class="line">1、内存元数据metadata 在内存中存储了一份完整的元数据，包括目录树结构，以及文件和数据块和副本存储地的映射关系;为了提高读写响应。</span><br><span class="line">2、磁盘元数据 其次是在磁盘中也存储了一份完整的元数据，为了提高数据安全性。</span><br><span class="line">有三种格式:</span><br><span class="line">	磁盘元数据镜像文件:fsimage_0000000000000000555 </span><br><span class="line">	历史编辑日志:edits_0000000000000000001-0000000000000000018 </span><br><span class="line">	数据预写操作日志文件edits_inprogress_0000000000000000556</span><br><span class="line">	</span><br><span class="line">另外存放磁盘元数据的目录中，还有一个文件:VERSION(存放hdfs集群的版本信息)</span><br><span class="line"></span><br><span class="line">查看hdfs文件</span><br><span class="line">	hdfs oev -i edits_0000000000000000482-0000000000000000483 -o edits.xml </span><br><span class="line">	cat edits.xml</span><br><span class="line">查看fsimage镜像文件信息:</span><br><span class="line">	hdfs oiv -i fsimage_0000000000000000348 -p XML -o fsimage.xml </span><br><span class="line">	cat fsimage.xml</span><br><span class="line"></span><br><span class="line">6.4. 元数据的CheckPoint</span><br><span class="line">	每隔一段时间，会由 SecondaryNamenode 将 NameNode 上积累的所有 edits 和一个最新的 fsimage</span><br><span class="line">下载到本地，并加载到内存进行 merge(这个过程称为 checkpoint)</span><br><span class="line">			</span><br></pre></td></tr></table></figure>
</li>
<li><p>NameNode工作机制之CheckPoint详细过程图解:</p>
<img src="/Users/wangfeng/Library/Application Support/typora-user-images/image-20200506230144060.png" alt="image-20200506230144060" style="zoom:50%;" />

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1、周期性发送请求给NN，获取fsimage和edits; </span><br><span class="line">2、NN收到请求后，生成一个空的edits.new文件 </span><br><span class="line">3、NM给SNN发送fsimage和edits </span><br><span class="line">4、SNN将fsimage文件加载到内存，合并edits文件 </span><br><span class="line">5、snm生成新的镜像文件fsimage.ckpt</span><br><span class="line">6、SNN发送fsimage.ckpt给NN </span><br><span class="line">7、NN将fsimage.ckpt替换fsimage文件，将edits.new重命名为edits文件</span><br><span class="line"></span><br><span class="line">6.5 CheckPoint触发配置</span><br><span class="line">dfs.namenode.checkpoint.check.period&#x3D;60 ##检查触发条件是否满足的频率，60秒 dfs.namenode.checkpoint.dir&#x3D;file:&#x2F;&#x2F;$&#123;hadoop.tmp.dir&#125;&#x2F;dfs&#x2F;namesecondary</span><br><span class="line">##以上两个参数做checkpoint操作时，secondary namenode的本地工作目录 dfs.namenode.checkpoint.edits.dir&#x3D;$&#123;dfs.namenode.checkpoint.dir&#125;</span><br><span class="line">dfs.namenode.checkpoint.max-retries&#x3D;3 ##最大重试次数 </span><br><span class="line">dfs.namenode.checkpoint.period&#x3D;3600 ##两次checkpoint之间的时间间隔3600秒 dfs.namenode.checkpoint.txns&#x3D;1000000 ##两次checkpoint之间最大的操作记录</span><br><span class="line"></span><br><span class="line">6.6. CheckPoint附带作用</span><br><span class="line">NameNode 和 SecondaryNamenode 的工作目录存储结构完全相同，所以，当 NameNode 故障退出 需要重新恢复时，可以从 SecondaryNamenode 的工作目录中将 fsimage 拷贝到 NameNode 的工作 目录，以恢复 NameNode 的元数据。</span><br><span class="line">但是请思考:从 SecondaryNamenode复制的fsimage能保证集群的元数据不丢失吗？</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>DataNode工作机制之工作职责</p>
<p>思考：</p>
<p>1、集群容量不够，怎么扩容?<br>2、如果有一些 DataNode 宕机，该怎么办?<br>3、DataNode 明明已启动，但是集群中的可用 DataNode 列表中就是没有，怎么办?    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">存储管理用户文件块的数据</span><br><span class="line">定期向NameNode汇报自身所持有的block信息(通过心跳信息上报)</span><br><span class="line">执行真正的读数据请求</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;!—HDFS集群数据冗余块的自动删除时长，单位ms，默认一个小时 --&gt;</span><br><span class="line">	&lt;name&gt;dfs.blockreport.intervalMsec&lt;&#x2F;name&gt;</span><br><span class="line">	&lt;value&gt;3600000&lt;&#x2F;value&gt;</span><br><span class="line">	&lt;description&gt;Determines block reporting interval in milliseconds.</span><br><span class="line">	&lt;&#x2F;description&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>DataNode工作机制之DataNode 掉线判断时限</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">datanode 进程死亡或者网络故障造成 DataNode 无法与 NameNode 通信，NameNode 不会立即把 该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。 HDFS 默认的超时时长为 10min+30s</span><br><span class="line">如果定义超时时间为 timeout，则超时时长的计算公式为:</span><br><span class="line">	timeout &#x3D; 2 * heartbeat.recheck.interval + 10 * dfs.heartbeat.interval</span><br><span class="line">默认的heartbeat.recheck.interval大小为5分钟，dfs.heartbeat.interval&#96; 默认为3秒</span><br><span class="line"></span><br><span class="line">eg. 如果heartbeat.recheck.interval设置为5000(毫秒)，dfs.heartbeat.interval设置为3(秒，默认)，则总的超时时间为40秒。</span><br><span class="line"></span><br><span class="line">注意： hdfs-site.xml heartbeat.recheck.interval的单位是毫秒dfs.heartbeat.interval单位是秒</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>SecondaryNamenode工作机制</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SecondaryNamenode的作用就是分担 NameNode 的合并元数据的压力。所以在配置 SecondaryNamenode 的工作节点时，一定切记，不要和 NameNode 处于同一节点。但事实上，只有 在普通的伪分布式集群和分布式集群中才有会 SecondaryNamenode 这个角色，在 HA 或者联邦集群 中都不再出现该角色。在 HA 和联邦集群中，都是由 StandbyNameNode 承担。</span><br><span class="line">1、辅助 NameNode，分担其工作量，减轻 NameNode 压力 </span><br><span class="line">2、定期合并 fsimage 和 edits，并推送给 NameNode。 以缩短集群启动的时间。</span><br><span class="line">3、在紧急情况下，可辅助恢复 NameNode。</span><br><span class="line">当NameNode(以下简称NN)失效的时候，Secondary NN并无法立刻提供服务，Secondary NN甚至无 法保证数据完整性:如果NN数据丢失的话，在上一次合并后的文件系统的改动会丢失。</span><br></pre></td></tr></table></figure>
</li>
<li><p>Client 工作机制</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Client:就是客户端。</span><br><span class="line">1、文件切分。文件上传 HDFS 的时候，Client 将文件切分成 一个一个的Block，然后进行存储。 </span><br><span class="line">2、与 NameNode 交互，获取文件的位置信息。</span><br><span class="line">3、与 DataNode 交互，读取或者写入数据。</span><br><span class="line">4、Client 提供一些命令来管理 HDFS，比如启动或者关闭HDFS。</span><br><span class="line">5、Client 可以通过一些命令来访问 HDFS。</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS的高可用机制</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">一个典型的HA集群，两个单独的机器配置为NameNodes，在任何时候，一个 NameNode 处于活动状 态，另一个处于待机状态，活动的 NameNode 负责处理集群中所有客户端的操作，待机时仅仅作为一 个slave，保持足够的状态，如果有必要提供一个快速的故障转移。</span><br><span class="line">为了保持备用节点与活动节点状态的同步，目前的实现需要两个节点同时访问一个共享存储设备(例如 从NASNFS挂载)到一个目录。将有可能在未来的版本中放宽此限制。</span><br><span class="line">当活动节点对命名空间进行任何修改，它将把修改记录写到共享目录下的一个日志文件，备用节点会监 听这个目录，当发现更改时，它会把修改内容同步到自己的命名空间。备用节点 在故障转移时，它将 保证已经读取了所有共享目录内的更改记录，保证在发生故障前的状态 与活动节点保持完全一致。</span><br><span class="line">为了提供快速的故障转移，必须保证备用节点有最新的集群中块的位置信息，为了达到这一点， Datanode 节点需要配置两个 nameNode 的位置，同时发送块的位置信息和心跳信息到两个 nameNode。</span><br><span class="line">任何时候只有一个 namenode 处于活动状态，对于HA集群的操作是至关重要的，否则两个节点之间的 状态就会产生冲突，数据丢失或其它不正确的结果，为了达到这个目的或者所谓的 “裂脑场景” 出现，管 理员必须为共享存储配置至少一个(fencing)方法。在宕机期间， 如果不能确定之间的活动节点已经 放弃活动状态，fencing进程负责中断以前的活动节点编辑存储的共享访问。这可以防止任何进一步的 修改命名空间，允许新的活动节点安全地进行故障转移。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1、只有一个 NameNode 是 Active 的，并且只有这个 Active NameNode 能提供服务，该Active NameNode 宕机不可用的话，可以考虑让 Standby NameNode 切换成 Active 来提供服务。 </span><br><span class="line">2、提供手动 Failover，在升级过程中，Failover 在 NameNode-DataNode 之间写不变的情况下才能生 效。</span><br><span class="line">3、在之前的 NameNode 重新恢复之后，不能提供 failback。</span><br><span class="line">4、数据一致性比 Failover 更重要。</span><br><span class="line">5、尽量少用特殊的硬件。</span><br><span class="line">6、HA 的设置和Failover 都应该保证在两者操作错误或者配置错误的时候，不得导致数据损坏。 </span><br><span class="line">7、NameNode 的短期垃圾回收不应该触发 Failover。</span><br><span class="line">8、DataNode 会同时向 Active NameNode 和 Standby NameNode 汇报块的信息。</span><br><span class="line">9、Active NameNode 和 Standby NameNode 通过 NFS 备份 MetaData 信息到一个磁盘上面。</span><br></pre></td></tr></table></figure>
</li>
<li><p>ZooKeeper 底层组件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">znode文件系统</span><br><span class="line">watch监听系统</span><br><span class="line"></span><br><span class="line">所以Zookeeper在hadoop中的作用？ </span><br><span class="line">	a. 帮hdfs存储一些数据 （active 和 standby  共享元数据系统）</span><br><span class="line">	b. 监控&#x2F;调节hdfs的状态 （active 挂掉 马上将standby切换成active）</span><br></pre></td></tr></table></figure>
</li>
<li><p>ZooKeeper 底层组件之Znode文件系统</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">ZooKeeper 的命名空间就是 ZooKeeper 应用的文件系统，类似于 Linux 的文件系统，也是树状</span><br><span class="line">	目的：可以确定每个路径都是唯一的</span><br><span class="line">	注意：对于命名空间的操作必须都是绝对路径操作。</span><br><span class="line">	与Linux文件系统不同的是</span><br><span class="line">		1. Linux 文件系统有目录和文件的区别，而 ZooKeeper 统一叫做 znode</span><br><span class="line">		2. 一个 znode 节点下可以包含子 znode，同时该节点也可以存储数据。 </span><br><span class="line">			 znode 只适合存储非常小量的数据，不能超过1M，最好小于1K。</span><br><span class="line">		</span><br><span class="line">Znode的分类</span><br><span class="line">	按照生命周期（节点的存活时间）可以分为:</span><br><span class="line">			短暂(ephemeral)(断开连接自己删除)</span><br><span class="line">			持久(persistent)(断开连接不删除，默认情况) </span><br><span class="line">	按照是否自带序列编号可以分为:</span><br><span class="line">			SEQUENTIAL(带自增序列编号，由父节点维护) </span><br><span class="line">			非SEQUENTIAL(不带自增序列编号，默认情况)</span><br><span class="line">	注意： 顺序节点为节点的一种特性，也就是，持久节点和临时节点都可以设置为顺序节点</span><br><span class="line">				这样一来，znode一共有4种类型：持久的、临时的，持久顺序的，临时顺序的。</span><br><span class="line">				每次创建顺序节点时，zk都会在路径后面自动添加上10位的数字（计数器），例如 </span><br><span class="line">				&lt; path &gt;0000000001，&lt; path &gt;0000000002，……这个计数器可以保证在同一个父节点下是唯一的。</span><br><span class="line">	</span><br><span class="line">	四种节点详细说明：</span><br><span class="line">	1. PERSISTENT 持久化 znode 节点，一旦创建这个 znode 节点，存储的数据不会 主动消失，除非是</span><br><span class="line">		客户端主动 delete</span><br><span class="line">	2. PERSISTENT_SEQUENTIAL  持久自增顺序编号的 znode 节点，比如 ClientA 去 zookeeper 	</span><br><span class="line">		service上建立一个znode名字叫做&#x2F;zk&#x2F;conf，指定了这种类型的节点后zk会创建 &#x2F;zk&#x2F;conf0000000000，</span><br><span class="line">		ClientB 再 去创建就是创建 &#x2F;zk&#x2F;conf0000000001，ClientC是创建&#x2F;zk&#x2F;conf0000000002，以后任意 </span><br><span class="line">		Client 来创建这个 znode 都会 得到一个比当前 zookeeper 命名空间最大 znode编号 +1 的 znode，</span><br><span class="line">		也就说任意一个 Client 去创建 znode 都是保证得到的 znode 编号是递增的，而且是唯一的 znode 节点</span><br><span class="line">	3. EPHEMERAL 临时 znode 节点，Client 连接到 zk service 的时候会建立一个 session，之后用这个</span><br><span class="line">  	zk 连接实例在该 session 期间创建该类型的 znode，一旦 Client 关闭了 zookeeper 的连接，服务器</span><br><span class="line">  	就会清除 session，然后这个 session 建立的 znode 节点都会从命名空间消 失。总结就是，这个类型的</span><br><span class="line">    znode 的生命周期是和 Client 建立的 连接一样的。比如 ClientA 创建了一个EPHEMERAL的&#x2F;zk&#x2F;conf</span><br><span class="line">    的 znode 节点，一旦 ClientA 的 zookeeper 连接关闭，这个 znode 节点就会消失。整个zookeeper</span><br><span class="line">    service命名空间里就会删 除这个znode节点</span><br><span class="line">	4. EPHEMERAL_SEQUENTIAL 临时自增顺序编号节点znode节点编号会自动增加但是会随session消失而消失</span><br><span class="line">	</span><br><span class="line">	https:&#x2F;&#x2F;blog.csdn.net&#x2F;lihao21&#x2F;article&#x2F;details&#x2F;51810395				</span><br></pre></td></tr></table></figure>
</li>
<li><p>ZooKeeper 底层组件之Watch监听系统</p>
<img src="/Users/wangfeng/Library/Application Support/typora-user-images/image-20200507080745974.png" alt="image-20200507080745974" style="zoom:50%;" />

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">客户端注册监听它关心的目录节点，当目录节点发生变化(数据改变、节点删除、子目录节点增加删 除)时，ZooKeeper 会通知客户端。监听机制保证 ZooKeeper 保存的任何的数据的任何改变都能快速的响应到监听了该节点的应用程序。监听器的工作机制，其实是在客户端会专门创建一个监听线程，在本机的一个端口上等待ZooKeeper集群发送过来事件。</span><br><span class="line"></span><br><span class="line">监听工作原理:</span><br><span class="line">	ZooKeeper 的 Watcher 机制主要包括客户端线程、客户端 WatcherManager、 Zookeeper 服务器三部分。客户端在向 ZooKeeper 服务器注册的同时，会将 Watcher 对象存储在客户 端的 WatcherManager 当中。当 ZooKeeper 服务器触发 Watcher 事件后，会向客户端发送通知，客 户端线程从 WatcherManager 中取出对应的 Watcher 对象来执行回调逻辑。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>ZooKeeper 底层组件之典型应用场景</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">a. 命名服务</span><br><span class="line">	 ZooKeeper可以实现一套分布式全局唯一ID的分配机制</span><br><span class="line">b. 配置管理</span><br><span class="line">	 程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。现在把这些 配置全部放到</span><br><span class="line">	 ZooKeeper上去，保存在 ZooKeeper 的某个目录节点中，然后所有相关应用程序对 这个目录节点进行监听，</span><br><span class="line">	 一旦配置信息发生变化，每个应用程序就会收到 ZooKeeper 的通知，然 后从 ZooKeeper 获取新的配置信息</span><br><span class="line">	 应用到系统中就好。</span><br><span class="line">c. 集群管理</span><br><span class="line">	 群管理无在乎两点:是否有机器退出和加入、选举master。</span><br><span class="line">d. 分布式锁</span><br><span class="line">	 锁服务可以分为两三类</span><br><span class="line">		一个是写锁，对写加锁，保持独占，或者叫做排它锁，独占锁 </span><br><span class="line">		一个是读锁，对读加锁，可共享访问，释放锁之后才可进行事务操作，也叫共享锁 </span><br><span class="line">		一个是控制时序，叫时序锁</span><br><span class="line">	解释：</span><br><span class="line">		1. 对于第一类，我们将 ZooKeeper 上的一个znode看作是一把锁，通过 createznode() 的方式来实</span><br><span class="line">    	 现。所有客户端都去创建 &#x2F;distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。 </span><br><span class="line">    	 用完删除掉自己创建的 &#x2F;distribute_lock 节点就释放出锁。</span><br><span class="line">		2. 对于第二类，&#x2F;distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，</span><br><span class="line">			 和选 Master 一样，编号最小的获得锁，用完删除，依次有序</span><br><span class="line">队列管理</span><br><span class="line">	两种类型的队列:</span><br><span class="line">		1、同步队列:当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 </span><br><span class="line">		2、先进先出队列:队列按照 FIFO 方式进行入队和出队操作。</span><br><span class="line">	解释：</span><br><span class="line">		第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 </span><br><span class="line">		第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。</span><br></pre></td></tr></table></figure>
</li>
<li><p>ZooKeeper的设计目的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">zookeeper 以一个集群的方式对外提供协调服务，集群内部 的所有节点都保存了一份完整的数据，其中一个主节点用来做集群管理提供写数据服务，其他的从节点 用来同步数据，提供读数据服务。这些从节点必须保持和主节点的数据状态一致。</span><br><span class="line"></span><br><span class="line">数据复制的好处:</span><br><span class="line">1、容错:一个节点出错，不至于让整个集群无法提供服务 </span><br><span class="line">2、扩展性:通过增加服务器节点能提高 ZooKeeper 系统的负载能力，把负载分布到多个节点上 </span><br><span class="line">3、高性能:客户端可访问本地 ZooKeeper 节点或者访问就近的节点，依次提高用户的访问速度</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="37">
<li><p>ZooKeeper的设计特点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">1. 最终一致性</span><br><span class="line">	 client 不论连接到哪个 Server，展示给它都是同一个数据视图，这是 ZooKeeper 最重要的性能。</span><br><span class="line">2. 可靠性</span><br><span class="line">	 具有简单、健壮、良好的性能，如果消息 message 被到一台服务器接受，那么它将被所有的服务器接受。</span><br><span class="line">3. 实时性</span><br><span class="line">	 ZooKeeper 保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于</span><br><span class="line">	 网络延时等原因，ZooKeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读</span><br><span class="line">	 数据之前调用 sync() 接口。</span><br><span class="line">4. 等待无关(wait-free)</span><br><span class="line">	 慢的或者失效的 client 不得干预快速的 client 的请求，使得每个 client 都能有效的等待。</span><br><span class="line">5. 原子性</span><br><span class="line">	 更新只能成功或者失败，没有中间状态。</span><br><span class="line">6. 顺序性</span><br><span class="line">	 包括全局有序和偏序两种:</span><br><span class="line">		1、全局有序:</span><br><span class="line">			如果在一台服务器上消息 a 在消息 b 前发布，则在所有 Server 上消息 a 都将在消息 b 前被发布;</span><br><span class="line">		2、偏序:</span><br><span class="line">			指如果一个消息 b 在消息 a 后被同一个发送者发布，a 必将排在 b 前面。</span><br></pre></td></tr></table></figure>
</li>
<li><p>Zookeeper的集群角色解析</p>
<img src="/Users/wangfeng/Library/Application Support/typora-user-images/image-20200507082432134.png" alt="image-20200507082432134" style="zoom:50%;" />

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">集群的角色有可以有三种:leader, follower, observe</span><br></pre></td></tr></table></figure>
</li>
<li><p>Zookeeper原理之Paxos算法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">分布式系统中的节点通信存在两种模型: </span><br><span class="line">	共享内存(Shared Memory)</span><br><span class="line">	消息传递(Messages Passing)</span><br><span class="line"></span><br><span class="line">Paxos算法是莱斯利•兰伯特(英语:Leslie Lamport)于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法。</span><br><span class="line"></span><br><span class="line">基于消息传递的节点通信缺点：</span><br><span class="line">	基于消息传递通信模型的分布式系统，不可避免的会发生以下错误:进程可能会慢、被杀死或者重启， 消息可能会</span><br><span class="line">	延迟、丢失、重复，在基础Paxos场景中，先不考虑可能出现消息篡改即拜占庭错误 (Byzantine failure，即</span><br><span class="line">	虽然有可能一个消息被传递了两次，但是绝对不会出现错误的消息)的情况。</span><br><span class="line"></span><br><span class="line">Paxos算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发 生以上任何异常，都不会破坏决议一致性。</span><br><span class="line"></span><br><span class="line">Paxos算法使用一个希腊故事来描述，在Paxos中，存在三种角色，分别为</span><br><span class="line">	Proposer(提议者，用来发出提案proposal)， </span><br><span class="line">	Acceptor(接受者，可以接受或拒绝提案)， </span><br><span class="line">	Learner(学习者，学习被选定的提案，当提案被超过半数的	Acceptor接受后为被批准)。</span><br><span class="line">Paxos要解决的问题:</span><br><span class="line">	决议(value)只有在被proposer提出后才能被批准 </span><br><span class="line">	在一次Paxos算法的执行实例中，只批准(chose)一个value </span><br><span class="line">	learner只能获得被批准(chosen)的value</span><br><span class="line">ZooKeeper的选举算法有两种:</span><br><span class="line">	一种是基于 Basic Paxos(Google Chubby采用)实现的，</span><br><span class="line">	一种是基于 Fast Paxos(ZooKeeper采用)算法实现的。</span><br><span class="line">	ZooKeeper默认的选举算法为Fast Paxos，并且ZooKeeper在3.4.0版本后只保留了 FastLeaderElection 算法。</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">为了保证事务的顺序一致性，zookeeper 采用了递增的事务 id 号(zxid)来标识事务。所有的提议 (proposal)都在被提出的时候加上了 zxid。实现中 zxid 是一个 64 位的数字，它高32位是 epoch 用 来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch，标识当前属于那 个 leader 的统治时期。低 32 位用于递增计数。</span><br><span class="line"></span><br><span class="line">Basic Paxos流程:</span><br><span class="line">1、选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的 Server</span><br><span class="line">2、选举线程首先向所有Server发起一次询问(包括自己)</span><br><span class="line">3、选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的 serverid(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息 (serverid,zxid)，并将这些信息存储到当次选举的投票记录表中</span><br><span class="line">4、收到所有Server回复以后，就计算出id最大的那个Server，并将这个Server相关信息设置成下一次 要投票的Server</span><br><span class="line">5、线程将当前id最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n&#x2F;2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的 状态，否则，继续这个过程，直到leader被选举出来。</span><br><span class="line"></span><br><span class="line">总结：</span><br><span class="line">	1、要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1 </span><br><span class="line">	2、且存活的Server的数目不得少于n+1</span><br><span class="line"></span><br><span class="line">全新集群选主</span><br><span class="line">	1、服务器1启动，此时只有它一台服务器启动了，它发出去的报没有任何响应，所以它的选举状态一直是LOOKING状态</span><br><span class="line">2、服务器2启动，它与最开始启动的服务器1进行通信，互相交换自己的选举结果，由于两者都没有历史数据，所以id	值较大的服务器2胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的 半数以上是3)，所以服务器1、2还是继续保持LOOKING状态</span><br><span class="line">	3、服务器3启动，根据前面的理论分析，服务器3成为服务器1,2,3中的老大，而与上面不同的是，此时有 三台服务器(超过半数)选举了它，所以它成为了这次选举的leader</span><br><span class="line">	4、服务器4启动，根据前面的分析，理论上服务器4应该是服务器1,2,3,4中最大的，但是由于前面已经有 半数以上的服务器选举了服务器3，所以它只能接收当小弟的命了</span><br><span class="line">	5、服务器5启动，同4一样，当小弟</span><br><span class="line">	</span><br><span class="line">总结:zookeeper server的三种工作状态</span><br><span class="line">	LOOKING:当前Server不知道leader是谁，正在搜寻，正在选举 </span><br><span class="line">	LEADING:当前Server即为选举出来的leader，负责协调事务 </span><br><span class="line">	FOLLOWING:leader已经选举出来，当前Server与之同步，服从leader的命令</span><br><span class="line">	</span><br><span class="line">非全新集群选主</span><br><span class="line">	1、逻辑时钟小的选举结果被忽略，重新投票 </span><br><span class="line">	2、统一逻辑时钟后，数据version大的胜出 </span><br><span class="line">	3、数据version相同的情况下，server id大的胜出</span><br><span class="line">	</span><br><span class="line">逻辑时钟:</span><br><span class="line">	这个值从0开始递增，每次选举对应一个值，也就是说:如果在同一次选举中，那么这个值 应该是一致的;逻辑时钟</span><br><span class="line">	值越大，说明这一次选举 leader 的进程更新，也就是每次选举拥有一个 zxid，投票结果只取 zxid 最新的</span><br><span class="line">	数据 </span><br><span class="line">version:</span><br><span class="line">	数据新的 version 就大，数据每次更新都会更新 version</span><br><span class="line">server id:</span><br><span class="line">	就是我们配置的 myid 中的值，每个机器一个</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="40">
<li><p>Zookeeper原理之ZAB协议</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ZooKeeper 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做 ZAB协议(Zookeeper Atomic BroadCast)。</span><br><span class="line"></span><br><span class="line">ZAB协议有两种模式</span><br><span class="line">崩溃恢复模式(选主)</span><br><span class="line">	当服务启动或者在领导者崩溃后，ZAB就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和</span><br><span class="line">	leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和follower之间具有相同的系 统状态。</span><br><span class="line">原子广播模式(同步)</span><br><span class="line">	当ZooKeeper集群选举出leader同步完状态退出恢复模式之后，便进入了原子广播模式。所有的写请求都被转</span><br><span class="line">	发给leader，再由leader将更新proposal广播给follower</span><br><span class="line">	</span><br><span class="line"></span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="41">
<li><p>Zookeeper原理之数据同步</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">选完 leader 以后，zk就进入状态同步过程。</span><br><span class="line">	1、leader等待server连接; </span><br><span class="line">	2、follower连接leader，将最大的zxid发送给leader; </span><br><span class="line">	3、leader根据follower的zxid确定同步点;</span><br><span class="line">	4、完成同步后通知follower 已经成为uptodate状态; </span><br><span class="line">	5、follower收到uptodate消息后，又可以重新接受client的请求进行服务了。</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="42">
<li><p>关于MapperReduce执行机制</p>
<ol>
<li><p>按照数据处理过程来说</p>
<img src="/Users/wangfeng/Library/Application Support/typora-user-images/image-20200511080727192.png" alt="image-20200511080727192" style="zoom:40%;" />
</li>
<li><p>按照处理过程中mapperreduce参与的api来说</p>
<img src="/Users/wangfeng/Library/Application Support/typora-user-images/image-20200511080756953.png" alt="image-20200511080756953" style="zoom:40%;" />
</li>
</ol>
</li>
<li><p>MapReduce中的序列化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">序列化：将结构化对象转换成字节流以便于进行网络传输或写入持久存储的过程。</span><br><span class="line">反序列化：将字节流转换为一系列结构化对象的过程。</span><br><span class="line">序列化作用：	</span><br><span class="line">	1、作为一种持久化格式。 </span><br><span class="line">	2、作为一种通信的数据格式。 </span><br><span class="line">	3、作为一种数据拷贝、克隆机制。</span><br><span class="line">	</span><br><span class="line">MR序列化与java序列化</span><br><span class="line">	Java 的序列化是一个重量级序列化框架(Serializable)，一个对象被序列化后，会附带很多额外的信息</span><br><span class="line">	(各种校验信息，header，继承体系等)，不便于在网络中高效传输</span><br><span class="line">	Hadoop 自己开发了一 套序列化机制(参与序列化的对象的类都要实现 Writable 接口)，精简，高效</span><br><span class="line"></span><br><span class="line">需要将自定义的 bean 作为 key，则要实现 WritableComparable 接口，因为 Writerable 接口不具 备比较功能，而 MapReduce 框中的 shuffle 过程一定会对 key 进行排序，所以还需要指定排序规则</span><br><span class="line">如果自定义的 bean 只是作为 value，那么只需要实现 Writable 接口即可</span><br><span class="line"></span><br><span class="line">总结：</span><br><span class="line">	1、key必须实现 WritableComparable 接口 </span><br><span class="line">	2、value必须要实现 Writable 接口</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>MapReduce之Combiner</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">作用：</span><br><span class="line">	是在 mapTask 之后 给mapTask 的结果进行局部汇总，是一个本地化的reduce操作，主要是在 mapTask 计算得到结果文件 前做一个简单的合并重复key值的操作以减轻 reduceTask 的计算负载，减少网络传输。</span><br><span class="line">	eg. 中国统计国 家GDP，其实可以每个市县先把GDP发送给省做汇总，再发送给国家统计局，而不是把所有的市县GDP 都发送给国家统计局造成国家统计局的汇总压力。</span><br><span class="line">	</span><br><span class="line">	因为Combiner 逻辑和 Reducer 是一样的所以在实现的时候直接实现Reducer接口即可</span><br><span class="line">	job.setCombinerClass(FlowSumCombine.class)</span><br><span class="line">	</span><br><span class="line">Combiner和Reducer区别？</span><br><span class="line">	1、Combiner 和Reducer 的区别在于运行的位置:</span><br><span class="line">			Combiner 是在每一个MapTask所在的节点运行，每个Combiner 接收对应的 MapTask 结果进行局部汇总</span><br><span class="line">			Reducer 是接收全局所有 MapTask 的输出结果，进行最终的汇总</span><br><span class="line">	</span><br><span class="line">	2、Combiner 的输出 kv 类型应该跟 Reducer 的输入 kv 类型对应起来 Combiner 的输入 kv 类型应该跟</span><br><span class="line">  	 Mapper 的输出 kv 类型对应起来</span><br><span class="line">	3、Combiner 的使用要非常谨慎，因为 Combiner 在 MapReduce 过程中可能调用也可能不调用，可 能调一次也</span><br><span class="line">		 可能调多次，所以:Combiner使用的原则是:有或没有都不能影响业务逻辑，都不能影响 最终结果</span><br><span class="line">	4、sum 、count、avg、max、min中avg不适合做Combiner操作</span><br><span class="line">		 原因：任务分片后，每个 MapTask 保存有一定数据，如果要提前在 MapTask 上操作， 求出的是每个分区的平</span><br><span class="line">		 			均值，那么 MapTask 数据间不能有依赖关系。</span><br><span class="line">	</span><br></pre></td></tr></table></figure>
</li>
<li><p>MapReduce中之Sort</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MR程序在处理数据的过程中会对数据排序(map输出的kv对传输到reduce之前，会排序)，排序的依据 是map输出的key，所以，我们如果要实现自己需要的排序规则，则可以考虑将排序因素放到key中，让 key实现接口:WritableComparable，然后重写key的compareTo方法</span><br><span class="line"></span><br><span class="line">实现自定义的bean来封装流量信息，并将bean作为map输出的key来传输</span><br></pre></td></tr></table></figure>
</li>
<li><p>MapReduce多Job串联</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">一个稍复杂点的处理逻辑往往需要多个 MapReduce 程序串联处理，多Job的串联可以借助 MapReduce 框架的 JobControl 实现。</span><br><span class="line">JobControl由两个类组成:</span><br><span class="line">	Job </span><br><span class="line">	JobControl</span><br><span class="line">	</span><br><span class="line">	JobControl 类封装了一个 MapReduce 作业及其对应的 依赖关系，主要负责监控各个依赖作业的运行状态，一次更新自己的状态。作业刚开始处于 WAITING 状态。如果没有依赖作业或者所有作业均已运行完成，则进入 READY 状态。一旦进入 REDAY 状态，则 作业可被提交到 Hadoop 集群上运行，并进入 RUNNING 状态。在 RUNNING 状态下，根据作业运行 情况，可能进入 SUCCESS 或者 FAILED 状态。</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="47">
<li><p>MapReduce中的Partitioner</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MR中会将map输出的kv对，按照相同key分组，然后分发给不同的reducetask默认的分区组件HashPartitioner的分发规则为:根据key的hashcode%reducetask 数来分发，所以:如果要按照我们自己的需求进行分组，则需要改写数据分发(分组)组件 Partitioner</span><br></pre></td></tr></table></figure>
</li>
<li><p>MapReduce全局计数器（Counter）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">计数器是用来记录job的执行进度和状态的。它的作用可以理解为日志。我们可以在程序的某个位置插 入计数器，记录数据或者进度的变化情况。</span><br><span class="line">MapReduce计数器为我们提供一个窗口，用于观察MapReduce Job运行期的各种细节数据。对MapReduce性能调优很有帮助，MapReduce性能优化的评估大部分都是基于这些Counter的数值表现出来的。</span><br><span class="line">MapReduce自带了许多默认Counter，现在我们来分析这些默认Counter的含义，方便大家观察 Job结 果，如输入的字节数、输出的字节数、Map端输入&#x2F;输出的字节数和条数、Reduce端的输入&#x2F;输出的字节数和条数等</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="49">
<li><p>MapJoin-DistributedCache应用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">在各种实际业务场景中，按照某个关键字对两份数据进行连接是非常常见的。如果两份数据都比较小， 那么可以直接在内存中完成连接。如果是大数据量的呢?显然，在内存中进行连接会发生OOM。 MapReduce可以用来解决大数据量的链接</span><br><span class="line">MapReduce的Join操作主要分两类:MapJoin 和 ReduceJoin</span><br><span class="line"></span><br><span class="line">ReduceJoin:</span><br><span class="line">1、map阶段，两份数据data1和data2会被map分别读入，解析成以链接字段为key以查询字段为value 的key-value对，并标明数据来源是data1还是data2。 </span><br><span class="line">2、reduce阶段，reducetask会接收来自data1和data2的相同key的数据，在reduce端进行乘积链接， 最直接的影响是很消耗内存，导致OOM</span><br><span class="line"></span><br><span class="line">MapJoin:</span><br><span class="line">MapJoin 适用于有一份数据较小的连接情况。做法是直接把该小份数据直接全部加载到内存当中，按链接关键字建立索引。然后大份数据就作为 MapTask 的输入，对map()方法的每次输入都去内存当中直接去匹配连接。然后把连接结果按 key 输出，这种方法要使用 hadoop 中的 DistributedCache 把小份数据分布到各个计算节点，每个mapTask 执行任务的节点都需要加载该数据到内存，并且按连接关键 字建立索引</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="50">
<li><p>MapperReduce之自定义OutputFormat–数据分类输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">程序的关键点是要在一个MapReduce程序中根据数据的不同输出两类结果到不同目录，这类灵活的输</span><br><span class="line">出需求可以通过自定义OutputFormat来实现。</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="51">
<li><p>MapperReduce之自定义InputForma–小文件合并</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1、在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS </span><br><span class="line">2、在业务处理之前，在HDFS上使用MapReduce程序对小文件进行合并 </span><br><span class="line">3、在MapReduce处理时，可采用CombineFileInputFormat提高效率</span><br><span class="line"></span><br><span class="line">第二种方式使用 MapReduce 程序来对小文件进行合并</span><br><span class="line">	1、编写自定义的InputFormat </span><br><span class="line">	2、改写RecordReader，实现一次mapTask读取一个小文件的完整内容封装了一个KV对 </span><br><span class="line">	3、在Driver类中一定要设置使用自定义的InputFormat: 		</span><br><span class="line">	job.setInputFormatClass(WholeFileInputFormat.class)</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="52">
<li><p>MapperReduce中map个数以及reduce的个数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">1、mapTask到底多少个？</span><br><span class="line">	默认情况下： 这个程序的输入数据， 总共有多少个数据块，就会启动多少个MapTask</span><br><span class="line">	容错方案非常简单： 如果某个任务执行失败，会在另外一个副本所在节点启动任务继续执行</span><br><span class="line">		分布式计算应用程序</span><br><span class="line">			主管程序：MRAppMaster（跟踪，监控，协调，调度这些 task 运行）</span><br><span class="line">			小任务程序；MapTask ReduceTask</span><br><span class="line">		mapreduce还有一个推测执行机制</span><br><span class="line">			有一个参数可以控制</span><br><span class="line">			</span><br><span class="line"></span><br><span class="line">	如果说你想调整呢？</span><br><span class="line">	blocksize  minsize   maxsize</span><br><span class="line">	到底取那个值作为 默认的切割数据块执行计算的大小标准呢？</span><br><span class="line">	取这三个值的中间值</span><br><span class="line">		128M</span><br><span class="line">		1</span><br><span class="line">		29349234923498</span><br><span class="line"></span><br><span class="line">	minsize &gt; blocksize，   最终切块大小，就取  minsize</span><br><span class="line">	maxsize &lt; blocksize ,   最终切块大小，就取  maxsize</span><br><span class="line"></span><br><span class="line">	128G 内存 </span><br><span class="line">	每个Task 消耗 2G 内存</span><br><span class="line">	几乎可以启动50-60个 Task</span><br><span class="line"></span><br><span class="line">	mapper阶段有很多task,执行最慢的那个task决定了mapper阶段需要多长时间完成</span><br><span class="line"></span><br><span class="line">	100G的数据： 100个节点</span><br><span class="line">	128M： 几乎每个节点 8 个数据块</span><br><span class="line">	512M ： 几乎每个节点 2个数据块</span><br><span class="line"></span><br><span class="line">	充分利用集群的资源来执行计算</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2、reduceTask到底多少个？</span><br><span class="line"></span><br><span class="line">	更简单： 一句代码决定到底有多少个task</span><br><span class="line">	job.setNumReduceTasks(number);</span><br><span class="line"></span><br><span class="line">	1、第一宗情况：number &#x3D; 0</span><br><span class="line">		表示没有rducer阶段，只有mapper阶段。</span><br><span class="line">		业务没有聚合操作，只有映射操作</span><br><span class="line">		需求：把所有人的成绩，去掉小数点</span><br><span class="line">	2、第二种情况：number &#x3D; 1</span><br><span class="line">		最终的汇总，就只执行一个 reduceTask 任务</span><br><span class="line">		能实现全局排序。而且如果你的业务需求想要实现全局排序，</span><br><span class="line">		那就必须设置reduceTask为一个</span><br><span class="line">	3、第三种情况：&gt;1</span><br><span class="line">		如果设置到 number &gt; 1 那么是没法实现全局排序</span><br><span class="line">		每个renduceTask之间的数据执行汇总计算的时候，没有相关性。</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="53">
<li></li>
</ol>
<p>总结**</p>
<p>​    利用多个节点共同协作完成一项或多项具体业务功能的系统就是分布式系统。</p>
<pre><code>1. 系统由物理上不同分布的多个机器节点组成

   2. 系统的多个节点通过网络进行通信,协调彼此之间的工作
   3. 系统作为整体统一对外提供服务,其分布式细节对客户端透明</code></pre>
<hr>
<p>课堂笔记</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">map方法每调用一次，相当于一行操作一次</span><br><span class="line"></span><br><span class="line">reduce方法每调用一次，相当于每组进行操作一次</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">如果一行数据被分到2个块中，maptask会读取第二个快的数据，知道读取到换行符为止</span><br><span class="line"></span><br><span class="line">maptask 内存配置 1-2G（mr基于磁盘，需要内存不会很大）</span><br><span class="line">sparktask 内存配置5-10G （sparktask基于内存，给大一点内存）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">reduce task 到底多少个</span><br><span class="line">	job.setNumReduceTask(number)</span><br><span class="line">	</span><br><span class="line">	number</span><br><span class="line">		0: 没有reducer阶段,只有mapper阶段（业务没有聚合操作，只有映射阶段）</span><br><span class="line">		1: 只有一个reducetask,可以实现全局排序</span><br><span class="line">		&gt;1: 如果设置num &gt; 1 无法实现全局排序</span><br><span class="line">			每个reducetask之间的数据执行汇总计算的时候没有相关性</span><br><span class="line">			</span><br><span class="line">			</span><br><span class="line">		</span><br><span class="line">shuffle过程中只能根据key排序，如果想要根据value排序，需要自定义类，把这个类当作mr程序的key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">reduce和shuffle是同时存在的，如果有reduce阶段一定有shuffle阶段</span><br><span class="line">			</span><br><span class="line">有没有这种情况</span><br><span class="line">	有mapper阶段和reduce阶段，但是没有shuffle阶段，如果有这种情况，这种情况下是否有排序阶段</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">reduce有几个reducetask，那么输出就有几个文件，，如果全局有序一定是一个reducetask</span><br><span class="line"></span><br><span class="line">如果数据量太大怎么实现全局有序？怎么做？ 海量数据全局有序（使用多个reducetask）</span><br><span class="line"></span><br><span class="line">job设置reducetask数和分区数保持一致</span><br><span class="line">自定义分区一般自己是知道分区的个数的</span><br><span class="line"></span><br><span class="line">mapreduce程序的partition是在map阶段进行分区的</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">MR练习</span><br><span class="line">1. WordCount</span><br><span class="line">2. FlowSum</span><br><span class="line">3. FlowCombine</span><br><span class="line">4. FlowSort</span><br><span class="line">5. FlowPartition</span><br><span class="line">6. 多JOB串联</span><br><span class="line">7. day1题目--求学生成绩--普通版.txt</span><br><span class="line">8. day1题目--求学生平均成绩.txt</span><br><span class="line">9. day1题目--数据去重.txt</span><br><span class="line">10. day2题目--求访问最频繁的表.txt</span><br><span class="line">11. day2题目--求共同好友.txt</span><br><span class="line">12. day2题目--求互粉好友对.txt</span><br><span class="line">13. day2题目--数组排序并加序号.txt</span><br><span class="line">14. day2题目--versions变动版本.txt</span><br><span class="line">15. day3题目--求学生成绩--增强版.txt</span><br><span class="line"></span><br><span class="line">TopN的两种实现</span><br><span class="line">	1. 使用2个MR</span><br><span class="line">			a. 第一个MR 分区保存数据，且分区内是有序的 </span><br><span class="line">			b. 第二个MR 读取第一个MR中每个分区的数据取TopN</span><br><span class="line">	2. 使用1个MR</span><br><span class="line">			a. 需要自定义分组规则</span><br><span class="line">			</span><br><span class="line">eg. 统计每门课程参考学生的平均分，并且按课程存入不同的结果文件，要求一门课程一个结果文件，并且按平均分从高到低排序，分数保留一位小数</span><br><span class="line">	必须按照课程先排序，如果不按照课程排序，那么相同课程的的信息就不会放到一起，此时就没法按照该课程的所有的平均分进行排序（默认compareTo默认是排序规则，同时也是默认的分组规则）</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p>准备好新加的节点，分发hadoop安装包，启动进程即可（不推荐，会造成数据倾斜）</p>
<p>MR程序日志问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">	如果是local模式下，控制台会输出System.out.println(&quot;&quot;)的日志</span><br><span class="line">​	如果是集群模式下，控制台不会输出System.out.println(&quot;&quot;)日志，需要到hadoop的配置的log目录去找或者从yarn的界面点进去查看日志</span><br><span class="line">原因； 分布式集群下，MR程序会被发送到不同的节点运行，所以日志会在相应的节点输出，但是不会客户端（提交代码的节点）打印</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​    </p>
<p>Hive创建表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name            -- 小括号表示有 ｜ 表示或者</span><br><span class="line">  [COMMENT database_comment]</span><br><span class="line">  [LOCATION hdfs_path]</span><br><span class="line">  [MANAGEDLOCATION hdfs_path]</span><br><span class="line">  [WITH DBPROPERTIES (property_name&#x3D;property_value, ...)];</span><br><span class="line">  </span><br><span class="line">  -- ｜ 配合使用： (DATABASE|SCHEMA)有其中之一</span><br><span class="line">  </span><br><span class="line">  desc formatted movie; 查看表的元数据信息</span><br><span class="line">  show create table movie; 查看表的建表信息</span><br></pre></td></tr></table></figure>




    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item"></div>
      <div class="post-nav-item">
    <a href="/uncategorized/2020/10/22/hello-world.html" rel="next" title="Hello World">
      Hello World <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">阿峰</p>
  <div class="site-description" itemprop="description">啦啦啦</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">阿峰</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
